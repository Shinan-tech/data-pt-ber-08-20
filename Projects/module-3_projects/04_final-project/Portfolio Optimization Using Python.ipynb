{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio optimization of crypto currencies:\n",
    "a popular technique that financial and investment advisors use to help ensure that their clients are taking appropriate risk to meet their financial objectives.\n",
    "\n",
    "Section 1: Focusing on collecting the data necessary for analysis. Closing price for top10 coins according to marketcap. Use API CoinGecko to grab daily closing price in USD for 365 days during bear market (from 01.01.2019 - 31.12.2019).\n",
    "BTC ETH XRP ADA LTC BNB BCH XLM BSV EOS\n",
    "\n",
    "Section 2: Preparing the data to calculate a few different metrics: expected returns, expected volatility, and the sharpe ratio.\n",
    "\n",
    "Section 3: Building a simulation that will randomly generate results that we can use to help to determine the optimal results for a wide range of portfolios.\n",
    "\n",
    "Section 4: Taking this simulation, plot them using matplotlib, using scipy library to run an optimization algorthim that will return the best weights for our simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import reduce\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.optimize as sci_plt\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set some display option for Pandas\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"expand_frame_repr\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 Grabbing the data from CoinGecko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly to get the correct IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://api.coingecko.com/api/v3/\"\n",
    "url = base + \"/coins/list\"\n",
    "response = requests.get(url)\n",
    "results = response.json()\n",
    "df_list = pd.DataFrame(results).set_index(\"id\")\n",
    "df_list.to_csv(\"coins_list.csv\")\n",
    "# df_list[df_list['symbol'].str.match(\"bnb\")] : binancecoin\n",
    "# df_list[df_list['symbol'].str.match(\"bch\")] : bitcoin-cash\n",
    "# df_list[df_list['symbol'].str.match(\"bsv\")] : bitcoin-cash-sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly to generate a dataframe of all the prices from 01.Jan.19 to 31.12.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''all_coins = []\n",
    "base = \"https://api.coingecko.com/api/v3/\"\n",
    "ids = [\"bitcoin\", \"ethereum\", \"ripple\", \"cardano\", \"litecoin\", \"binancecoin\", \"bitcoin-cash\", \"stellar\", \"bitcoin-cash-sv\", \"eos\"]\n",
    "for coin in ids:\n",
    "    url = base + \"/coins/\"+ coin + \"/market_chart/range\"\n",
    "    param_dict = {\"id\":coin, \"vs_currency\":\"usd\", \"from\":\"1546297200\", \"to\":\"1577833200\"}\n",
    "    response = requests.get(url, params=param_dict)\n",
    "    results = response.json()\n",
    "    df = pd.DataFrame(results[\"prices\"], columns=[\"time\", coin])\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"ms\")\n",
    "    # df_all = pd.merge(df_all, df, how=\"left\", on=\"time\")\n",
    "    all_coins.append(df)\n",
    "\n",
    "all_coins_merged = reduce(lambda df1, df2: pd.merge(df1,df2, how=\"left\", on=\"time\"), all_coins)\n",
    "all_coins_merged.set_index(\"time\", inplace=True)\n",
    "\n",
    "all_coins_merged.to_csv(\"all_coins_2019.csv\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 Metrics\n",
    "When we compare the performance of an investment, we should take both return and risk into consideration. Most investors aren't okay with taking on high-levels of risk, so the goal is to find the best ratio of risk vs returns. Ideally, we are taking the most risk we are comfortable with and attempting to maximize those returns. That naturally leads to an important question, \"How do we measure risk?\". There are different ways to measure risk, in this workbook, we will use a very popular metric, the Sharpe Ratio. The Sharpe Ratio, is used as a measure for calculating risk-adjusted return and has been the industry standard for such calculations. The Sharpe Ratio allows us to quantify the relationship the average return earned in excess of the risk-free rate per unit of volatility or total risk.\n",
    "\n",
    "Mathematically, we define the Sharpe Ratio as the following:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\text{Sharpe Ratio} = \\frac{(R_p - R_f)}{\\sigma_p}\n",
    "\\end{equation*}$$\n",
    "Where:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\ R_p = \\text{Return of Portfolio} \\\\\n",
    "\\ R_f = \\text{Risk-Free Rate} \\\\\n",
    "\\ \\sigma_p = \\text{Standard Deviation of Portfolio's Excess Return} \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "To calculate the expected returns, we use the following formula:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\ R_p = (w_{1}r_{1}) + (w_{2}r_{2}) + \\cdots + (w_{n}r_{n})\n",
    "\\end{equation*}$$\n",
    "Where:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\ r_{i} = \\text{Return of Security i} \\\\\n",
    "\\ w_{i} = \\text{Weight of Security i} \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "To calculate the standard deviation of the protfolio, we use the following formula:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\ \\sigma_p = \\sqrt{(w_{i}^2 \\sigma_i^2) + (w_{j}^2 \\sigma_j^2) + (2w_{j}w_{i} p_{i,j} \\sigma_i \\sigma_j)}\n",
    "\\end{equation*}$$\n",
    "Where:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\ \\sigma_{i}  = \\text{Standard Deviation of Returns for Security i} \\\\\n",
    "\\ w_{i}  = \\text{Weight of Security i} \\\\\n",
    "\\ p_{i,j}  = \\text{Correlation Coefficent between the returns of asset i and asset j} \\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "all_coins_merged = pd.read_csv(\"all_coins_2019.csv\")\n",
    "all_coins_merged.set_index(\"time\", inplace=True)\n",
    "all_coins_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids = [\"bitcoin\", \"ethereum\", \"ripple\", \"cardano\", \"litecoin\", \"binancecoin\", \"bitcoin-cash\", \"stellar\", \"bitcoin-cash-sv\", \"eos\"]\n",
    "# log return over time\n",
    "# calculate the log returns\n",
    "log_return = np.log(1 + all_coins_merged.pct_change())\n",
    "\n",
    "# generate random weights\n",
    "random_weights = np.array(np.random.random(len(ids)))\n",
    "\n",
    "# generate rebalanced random weights, sum up to 1\n",
    "rebalanced_weights = random_weights / np.sum(random_weights)\n",
    "rebalanced_weights\n",
    "\n",
    "# calculate the expected returns and annualised it 365\n",
    "exp_ret = np.sum((log_return.mean() * rebalanced_weights)*365)\n",
    "\n",
    "# calculate the expected volatility and annualised it\n",
    "exp_vol = np.sqrt(\n",
    "    np.dot(\n",
    "        rebalanced_weights.T,\n",
    "        np.dot(\n",
    "            log_return.cov() * 365,\n",
    "            rebalanced_weights\n",
    "        )  \n",
    "    )\n",
    ")\n",
    "\n",
    "# calculate the sharpe ratio. Assumed that the risk free rate is 1%\n",
    "\n",
    "sharpe_ratio = (exp_ret - 0.01) / exp_vol\n",
    "\n",
    "# put the weights into a data frame for a better overview\n",
    "weights_df = pd.DataFrame(data={\n",
    "            \"random_weights\" : random_weights,\n",
    "            \"rebalanced_weights\" : rebalanced_weights\n",
    "})\n",
    "\n",
    "print(\"\")\n",
    "print(\"*\"*100)\n",
    "print(\"Portfolio Weights:\")\n",
    "print(\"*\"*100)\n",
    "print(weights_df)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# put the other metrics into a data frame for a better overview\n",
    "metrics_df = pd.DataFrame(data={\n",
    "            \"Expected Portfolio Returns\" : exp_ret,\n",
    "            \"Expected Portfolio Volatility\" : exp_vol,\n",
    "            \"Portfolio Sharpe Ratio\" : sharpe_ratio\n",
    "}, index=[0])\n",
    "print(\"\")\n",
    "print(\"*\"*100)\n",
    "print(\"Portfolio Metrics:\")\n",
    "print(\"*\"*100)\n",
    "print(metrics_df)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_return.hist(bins=100, figsize=(12,8))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_return.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 Portfolio Optimization: Monte Carlo\n",
    "\n",
    "By calculating the expected returns, the expected volatility and using the Sharpe Ratio to quantify how well the portfolio is allocated based on a risk perspective. The question is, \"if we know that we want to get a higher sharpe ratio, what is the portfolio allocation we need to achieve this?\"\n",
    "\n",
    "There are two ways to approach this question. \n",
    "1) We could test a bunch of different random allocations and see which ones produces the highest Sharpe Ratio.\n",
    "2) We could use mathematical optimization defined by some constrains to arrive at the optimial allocation -> Monte Carlo simulations\n",
    "\n",
    "Monte Carlo simulations are used to model the probability of different outcomes in a process that cannot easily be predicted due to the intervention of random variables. It is a technique used to understand the impact of risk and uncertainty in prediction and forcasting models.\n",
    "\n",
    "To do this, we can run the process we performed a couple thousands of time and store the results of each run in a data frame. once we've completed each run, we will find the allocations that produce the highest Sharpe Ratio and lowest Volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of times that we want to run the simulation\n",
    "\n",
    "num_of_simulations = 10000\n",
    "\n",
    "# set the weight array by using numpy zeros\n",
    "\n",
    "all_weights_array = np.zeros((num_of_simulations, len(ids)))\n",
    "\n",
    "# set the returns array by using numpy zeros\n",
    "\n",
    "ret_array = np.zeros(num_of_simulations)\n",
    "\n",
    "# set the volatility array by using numpy zeros\n",
    "vol_array = np.zeros(num_of_simulations)\n",
    "\n",
    "# set the sharpe ratio array by using numpy zeros\n",
    "\n",
    "sharpe_array = np.zeros(num_of_simulations)\n",
    "\n",
    "# start the simulation\n",
    "for trial in range(num_of_simulations):\n",
    "    \n",
    "    # firt, calculate the weights\n",
    "    weights = np.array(np.random.random(len(ids)))\n",
    "    weights = weights / np.sum(weights)\n",
    "    \n",
    "    # add the weights to the \"weights_array\"\n",
    "    all_weights_array[trial, :] = weights\n",
    "    \n",
    "    # calculate the expected log returns\n",
    "    ret_array[trial] = np.sum((log_return.mean() * weights)*365)\n",
    "    \n",
    "    # calculate the volatility\n",
    "    vol_array[trial] = np.sqrt(\n",
    "      np.dot(weights.T, np.dot(log_return.cov() * 365, weights))\n",
    "    )\n",
    "    \n",
    "    # calculate the sharpe ratio\n",
    "    sharpe_array[trial] = ret_array[trial] / vol_array[trial]\n",
    "\n",
    "# combine them \n",
    "simulations_data = [ret_array, vol_array, sharpe_array, all_weights_array]\n",
    "\n",
    "# create a Dataframe from the master array\n",
    "simulations_df = pd.DataFrame(data=simulations_data).T\n",
    "\n",
    "# give the columns name\n",
    "simulations_df.columns = [\"Returns\", \"Volatility\", \"Sharpe Ratio\", \"Portfolio Weights\"]\n",
    "\n",
    "# make sure the data types are correct\n",
    "simulations_df = simulations_df.infer_objects()\n",
    "\n",
    "# print out the results\n",
    "print(\"\")\n",
    "print(\"*\"*127)\n",
    "print(\"Simulations Reuslts:\")\n",
    "print(\"-\"*127)\n",
    "display(simulations_df.head())\n",
    "print(\"-\"*127)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the important metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the max sharpe ratio\n",
    "\n",
    "max_sharpe_ratio = simulations_df.loc[simulations_df[\"Sharpe Ratio\"].idxmax()]\n",
    "\n",
    "# grab the max return\n",
    "\n",
    "max_return = simulations_df.loc[simulations_df[\"Returns\"].idxmax()]\n",
    "\n",
    "# return the min volatility\n",
    "min_vol = simulations_df.loc[simulations_df[\"Volatility\"].idxmin()]\n",
    "\n",
    "print(\"\")\n",
    "print([\"bitcoin\", \"ethereum\", \"ripple\", \"cardano\", \"litecoin\", \"binancecoin\", \"bitcoin-cash\", \"stellar\", \"bitcoin-cash-sv\", \"eos\"])\n",
    "print(\"\")\n",
    "print(\"*\"*127)\n",
    "print(\"Max Sharpe Ratio:\")\n",
    "print(\"-\"*127)\n",
    "print(max_sharpe_ratio)\n",
    "print(\"-\"*127)\n",
    "\n",
    "print(\"\")\n",
    "print(\"*\"*127)\n",
    "print(\"Max Returns:\")\n",
    "print(\"-\"*127)\n",
    "print(max_return)\n",
    "print(\"-\"*127)\n",
    "\n",
    "print(\"\")\n",
    "print(\"*\"*127)\n",
    "print(\"Min Volatility:\")\n",
    "print(\"-\"*127)\n",
    "print(min_vol)\n",
    "print(\"-\"*127)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data on a scatter plot\n",
    "\n",
    "plt.scatter(\n",
    "    y=simulations_df[\"Returns\"],\n",
    "    x=simulations_df[\"Volatility\"],\n",
    "    c=simulations_df[\"Sharpe Ratio\"],\n",
    "    cmap=\"RdYlBu\"\n",
    ")\n",
    "\n",
    "# give title\n",
    "plt.title(\"Portfolio Returns vs Risks\")\n",
    "plt.colorbar(label=\"Sharpe Ratio\")\n",
    "plt.xlabel(\"Standard Deviation\")\n",
    "plt.ylabel(\"Returns\")\n",
    "\n",
    "# plot the max Sharpe ratio using a red star\n",
    "plt.scatter(\n",
    "    max_sharpe_ratio[1],\n",
    "    max_sharpe_ratio[0],\n",
    "    marker=\"X\",\n",
    "    color=\"r\",\n",
    "    s=600\n",
    ")\n",
    "\n",
    "# plot the min volatility using a red star\n",
    "plt.scatter(\n",
    "    min_vol[1],\n",
    "    min_vol[0],\n",
    "    marker=\"X\",\n",
    "    color=\"b\",\n",
    "    s=600\n",
    ")\n",
    "\n",
    "# plot the max return using a yellow star\n",
    "plt.scatter(\n",
    "    max_return[1],\n",
    "    max_return[0],\n",
    "    marker=\"X\",\n",
    "    color=\"y\",\n",
    "    s=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using unsupervised learning to classify the coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select only the real coin, exclude the non-coin ids\n",
    "# df_list = pd.read_csv(\"coins_list.csv\")\n",
    "# df_coins = df_list[~df_list[\"id\"].str.contains(\"-\")].reset_index()\n",
    "# df_coins.drop(columns=\"index\",inplace=True)\n",
    "# df_coins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I realized that if there is no-coin ids, the api will return NaN, as it is not easy to identify all the non-coin ids\n",
    "# I decided to grab everything from the coins_list and drop the columns with no values.\n",
    "df_list = pd.read_csv(\"coins_list.csv\")\n",
    "coin_ids = list(df_list[\"id\"])\n",
    "coin_ids_chunck = np.array_split(coin_ids, 130)\n",
    "coin_ids_chunck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# grab return from 01.Aug.19 to 31.Dec.19 for the coins in the list\n",
    "\n",
    "for i in range(91,131):\n",
    "    \n",
    "    base = \"https://api.coingecko.com/api/v3/\"\n",
    "    coins_return = []\n",
    "\n",
    "    for coin in coin_ids_chunck[i]:\n",
    "        try:\n",
    "     \n",
    "            url = base + \"/coins/\"+ coin + \"/market_chart/range\"\n",
    "            param_dict = {\"id\":coin, \"vs_currency\":\"usd\", \"from\":\"1564614000\", \"to\":\"1577833200\"}\n",
    "            response = requests.get(url, params=param_dict)\n",
    "            results = response.json()\n",
    "            \n",
    "            if results[\"prices\"] != []:\n",
    "                df_coin = pd.DataFrame(results[\"prices\"], columns=[\"time\", coin])\n",
    "                df_coin[\"time\"] = pd.to_datetime(df_coin[\"time\"], unit=\"ms\")\n",
    "                coins_return.append(df_coin)\n",
    "                coins_return_merged = reduce(lambda df1, df2: pd.merge(df1,df2, how=\"left\", on=\"time\"), coins_return)\n",
    "                coins_return_merged.set_index(\"time\", inplace=True)    \n",
    "\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    filename = \"\\\\chunk_coin_return\\\\df_\" + coin\n",
    "    coins_return_merged.to_csv(os.getcwd() + filename + \".csv\")      \n",
    "    time.sleep(30)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# merge all the files and drop the columns with more than 10% NA\n",
    "\n",
    "path = \"chunk_coin_return\"\n",
    "all_filenames = os.listdir(path)\n",
    "\n",
    "#combine all files in the list\n",
    "\n",
    "file_all = []\n",
    "for file in all_filenames:\n",
    "    filepath = path + \"/\" + file\n",
    "    df = pd.read_csv(filepath)\n",
    "    file_all.append(df)\n",
    "file_all\n",
    "\n",
    "coins_merged = reduce(lambda df1,df2: pd.merge(df1,df2, how=\"left\", on='time'), file_all)\n",
    "\n",
    "coins_merged.to_csv(\"coins_merged.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean the dataset \n",
    "\n",
    "coins_merged = pd.read_csv(\"coins_merged.csv\")\n",
    "col_name = coins_merged.columns[coins_merged.isnull().sum() > 20]\n",
    "coins_merged_clean = coins_merged.drop(columns=col_name)\n",
    "coins_merged_clean = coins_merged_clean.drop(coins_merged_clean.columns[0], axis=1)\n",
    "coins_merged_clean.set_index(\"time\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the annulised log return \n",
    "log_return = np.log(1 + coins_merged_clean.pct_change())\n",
    "# calculate the expected returns and annualised it 365\n",
    "annual_return_s = (log_return.mean() *365)\n",
    "df_coins = pd.DataFrame(annual_return_s)\n",
    "df_coins = df_coins.reset_index()\n",
    "df_coins.rename({\"index\":\"coins\", 0:\"annualised_return\"}, axis=1, inplace=True)\n",
    "df_coins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate daily standard deviation of returns\n",
    "daily_std = np.std(coins_merged_clean)\n",
    "  \n",
    "# annualized daily standard deviation\n",
    "std = daily_std * 365 ** 0.5\n",
    "\n",
    "df_std = pd.DataFrame(std)\n",
    "df_std = df_std.reset_index()\n",
    "df_std.rename({\"index\":\"coins\", 0:\"annualised_std\"}, axis=1, inplace=True)\n",
    "\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the daily log return and the daily voltility\n",
    "\n",
    "df_final = df_coins.merge(df_std, how=\"left\", on=\"coins\")\n",
    "df_final.set_index(\"coins\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a statistical summary\n",
    "\n",
    "desc_df = df_final.describe()\n",
    "\n",
    "# add the standard deviation metric\n",
    "desc_df.loc[\"+3_std\"] = desc_df.loc[\"mean\"] + (desc_df.loc[\"std\"] * 3)\n",
    "desc_df.loc[\"-3_std\"] = desc_df.loc[\"mean\"] - (desc_df.loc[\"std\"] * 3)\n",
    "\n",
    "# display \n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.nlargest(50, columns=\"annualised_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 2\n",
      "Silhouette Score: 0.9971488929495268\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 3\n",
      "Silhouette Score: 0.9974674957395956\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 4\n",
      "Silhouette Score: 0.9956657346076225\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 5\n",
      "Silhouette Score: 0.9938157296496429\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 6\n",
      "Silhouette Score: 0.9886719339974028\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 7\n",
      "Silhouette Score: 0.9887838900689842\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 8\n",
      "Silhouette Score: 0.9877545519075623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 9\n",
      "Silhouette Score: 0.9841574380451222\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 10\n",
      "Silhouette Score: 0.983818104948178\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 11\n",
      "Silhouette Score: 0.9785101772442049\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 12\n",
      "Silhouette Score: 0.977976276743916\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 13\n",
      "Silhouette Score: 0.9527073208344233\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 14\n",
      "Silhouette Score: 0.9526080349500818\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 15\n",
      "Silhouette Score: 0.9420754954606445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 16\n",
      "Silhouette Score: 0.9420418586287458\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 17\n",
      "Silhouette Score: 0.8353666174790783\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 18\n",
      "Silhouette Score: 0.816657754228341\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The number of clusters: 19\n",
      "Silhouette Score: 0.4152671717640269\n"
     ]
    }
   ],
   "source": [
    "# clustering coins by K-mean\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# create a dictionary to store our scores\n",
    "results_dict = {}\n",
    "\n",
    "# define the number of the iterations\n",
    "num_of_clusters = 20\n",
    "\n",
    "# run through each k\n",
    "\n",
    "for k in range(2, num_of_clusters):\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # define the key for this iteration\n",
    "    results_dict[k] = {}\n",
    "    \n",
    "    # create an instance of the kmeans model\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 0).fit(df_final)\n",
    "    \n",
    "    # define silhouette score\n",
    "    sil_score = metrics.silhouette_score(df_final, kmeans.labels_, metric = \"euclidean\")\n",
    "    \n",
    "    # store the different metrics\n",
    "    results_dict[k][\"silhouette_score\"] = sil_score\n",
    "    results_dict[k][\"inertia\"] = kmeans.inertia_\n",
    "    results_dict[k][\"score\"] = kmeans.score\n",
    "    results_dict[k][\"model\"] = kmeans\n",
    "    \n",
    "    # print out the results\n",
    "    \n",
    "    print(\"The number of clusters: {}\".format(k))\n",
    "    print(\"Silhouette Score: {}\".format(sil_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state = 0).fit(df_final)\n",
    "\n",
    "# fit model and predict clusters\n",
    "df_final['clusters'] = model.fit_predict(df_final)\n",
    "# # create scatter plot for samples from each cluster\n",
    "clusterval = df_final['clusters'].unique()\n",
    "for cluster in clusterval:\n",
    "    plt.scatter(df_final[df_final['clusters']==cluster][\"annualised_return\"], df_final[df_final['clusters']==cluster][\"annualised_std\"])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
