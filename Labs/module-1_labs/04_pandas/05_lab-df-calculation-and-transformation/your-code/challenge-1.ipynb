{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "\n",
    "In this challenge you will be working on **pokemons**. You will answer a series of questions in order to practice dataframe calculation, aggregation, and transformation.\n",
    "\n",
    "![Pokemon](pokemon.jpg)\n",
    "\n",
    "Follow the instructions below and enter your code.\n",
    "\n",
    "### Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set\n",
    "\n",
    "Import data set `Pokemon.csv` from the `your-code` directory of this lab. Read the data into a dataframe called `pokemon`.\n",
    "\n",
    "*Data set attributed to [Alberto Barradas](https://www.kaggle.com/abcsds/pokemon/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data set\n",
    "pokemon = pd.read_csv('Pokemon.csv')\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print first 10 rows of `pokemon`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>534</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>CharizardMega Charizard X</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>634</td>\n",
       "      <td>78</td>\n",
       "      <td>130</td>\n",
       "      <td>111</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>CharizardMega Charizard Y</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>634</td>\n",
       "      <td>78</td>\n",
       "      <td>104</td>\n",
       "      <td>78</td>\n",
       "      <td>159</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Squirtle</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                       Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1                  Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                    Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3                   Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3      VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4                 Charmander   Fire     NaN    309  39      52       43   \n",
       "5  5                 Charmeleon   Fire     NaN    405  58      64       58   \n",
       "6  6                  Charizard   Fire  Flying    534  78      84       78   \n",
       "7  6  CharizardMega Charizard X   Fire  Dragon    634  78     130      111   \n",
       "8  6  CharizardMega Charizard Y   Fire  Flying    634  78     104       78   \n",
       "9  7                   Squirtle  Water     NaN    314  44      48       65   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  \n",
       "5       80       65     80           1      False  \n",
       "6      109       85    100           1      False  \n",
       "7      130       85    100           1      False  \n",
       "8      159      115    100           1      False  \n",
       "9       50       64     43           1      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you look at a data set, you often wonder what each column means. Some open-source data sets provide descriptions of the data set. In many cases, data descriptions are extremely useful for data analysts to perform work efficiently and successfully.\n",
    "\n",
    "For the `Pokemon.csv` data set, fortunately, the owner provided descriptions which you can see [here](https://www.kaggle.com/abcsds/pokemon/home). For your convenience, we are including the descriptions below. Read the descriptions and understand what each column means. This knowledge is helpful in your work with the data.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| # | ID for each pokemon |\n",
    "| Name | Name of each pokemon |\n",
    "| Type 1 | Each pokemon has a type, this determines weakness/resistance to attacks |\n",
    "| Type 2 | Some pokemon are dual type and have 2 |\n",
    "| Total | A general guide to how strong a pokemon is |\n",
    "| HP | Hit points, or health, defines how much damage a pokemon can withstand before fainting |\n",
    "| Attack | The base modifier for normal attacks (eg. Scratch, Punch) |\n",
    "| Defense | The base damage resistance against normal attacks |\n",
    "| SP Atk | Special attack, the base modifier for special attacks (e.g. fire blast, bubble beam) |\n",
    "| SP Def | The base damage resistance against special attacks |\n",
    "| Speed | Determines which pokemon attacks first each round |\n",
    "| Generation | Number of generation |\n",
    "| Legendary | True if Legendary Pokemon False if not |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the distinct values across `Type 1` and `Type 2`\n",
    "\n",
    "Exctract all the values in `Type 1` and `Type 2`. Then create an array containing the distinct values across both fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'Fire', 'Ghost', 'Ice', 'Psychic', 'Bug', 'Rock', 'Flying', 'Fighting', 'Ground', 'Poison', 'Dragon', 'Grass', 'Fairy', 'Dark', 'Steel', 'Normal', 'Electric', 'Water'}\n"
     ]
    }
   ],
   "source": [
    "# enter your code here\n",
    "set1 = set(pokemon[\"Type 1\"])\n",
    "set2 = set(pokemon[\"Type 2\"])\n",
    "set3 = set1.union(set2)\n",
    "print(set3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column called `A/D Ratio` whose value equals to `Attack` devided by `Defense`\n",
    "\n",
    "For instance, if a pokemon has the Attack score 49 and Defense score 49, the corresponding `A/D Ratio` is 49/49=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.987952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.813008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.209302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  A/D Ratio  \n",
       "0       65       65     45           1      False   1.000000  \n",
       "1       80       80     60           1      False   0.984127  \n",
       "2      100      100     80           1      False   0.987952  \n",
       "3      122      120     80           1      False   0.813008  \n",
       "4       60       50     65           1      False   1.209302  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon[\"A/D Ratio\"] = pokemon[\"Attack\"] / pokemon[\"Defense\"]\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the pokemon with the highest `A/D Ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>386</td>\n",
       "      <td>DeoxysAttack Forme</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>50</td>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                Name   Type 1 Type 2  Total  HP  Attack  Defense  \\\n",
       "429  386  DeoxysAttack Forme  Psychic    NaN    600  50     180       20   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  A/D Ratio  \n",
       "429      180       20    150           3       True        9.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon[pokemon[\"A/D Ratio\"]==pokemon[\"A/D Ratio\"].max()]\n",
    "\n",
    "# pokemon.nlargest(1, 'A/D Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the pokemon with the lowest  `A/D Ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>213</td>\n",
       "      <td>Shuckle</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Rock</td>\n",
       "      <td>505</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>230</td>\n",
       "      <td>10</td>\n",
       "      <td>230</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #     Name Type 1 Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "230  213  Shuckle    Bug   Rock    505  20      10      230       10      230   \n",
       "\n",
       "     Speed  Generation  Legendary  A/D Ratio  \n",
       "230      5           2      False   0.043478  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon[pokemon[\"A/D Ratio\"]==pokemon[\"A/D Ratio\"].min()]\n",
    "# pokemon.nsmallest(1, 'A/D Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column called `Combo Type` whose value combines `Type 1` and `Type 2`.\n",
    "\n",
    "Rules:\n",
    "\n",
    "* If both `Type 1` and `Type 2` have valid values (not NaN), the `Combo Type` value should contain both values in the form of `<Type 1>-<Type 2>`. For example, if `Type 1` value is `Grass` and `Type 2` value is `Poison`, `Combo Type` will be `Grass-Poison`.\n",
    "\n",
    "* If `Type 1` has valid value but `Type 2` is not, `Combo Type` will be the same as `Type 1`. For example, if `Type 1` is `Fire` whereas `Type 2` is `NaN`, `Combo Type` will be `Fire`. You do not need to check for cases the other way round, those are the only two options.\n",
    "\n",
    "To solve this challenge, you will need to write a function which combines values from the rows, and then apply it to the dataframe (using df.apply, like we learned in the map-filter-reduce chapter)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function isna in module pandas.core.dtypes.missing:\n",
      "\n",
      "isna(obj)\n",
      "    Detect missing values for an array-like object.\n",
      "    \n",
      "    This function takes a scalar or array-like object and indicates\n",
      "    whether values are missing (``NaN`` in numeric arrays, ``None`` or ``NaN``\n",
      "    in object arrays, ``NaT`` in datetimelike).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    obj : scalar or array-like\n",
      "        Object to check for null or missing values.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    bool or array-like of bool\n",
      "        For scalar input, returns a scalar boolean.\n",
      "        For array input, returns an array of boolean indicating whether each\n",
      "        corresponding element is missing.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    notna : Boolean inverse of pandas.isna.\n",
      "    Series.isna : Detect missing values in a Series.\n",
      "    DataFrame.isna : Detect missing values in a DataFrame.\n",
      "    Index.isna : Detect missing values in an Index.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Scalar arguments (including strings) result in a scalar boolean.\n",
      "    \n",
      "    >>> pd.isna('dog')\n",
      "    False\n",
      "    \n",
      "    >>> pd.isna(pd.NA)\n",
      "    True\n",
      "    \n",
      "    >>> pd.isna(np.nan)\n",
      "    True\n",
      "    \n",
      "    ndarrays result in an ndarray of booleans.\n",
      "    \n",
      "    >>> array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
      "    >>> array\n",
      "    array([[ 1., nan,  3.],\n",
      "           [ 4.,  5., nan]])\n",
      "    >>> pd.isna(array)\n",
      "    array([[False,  True, False],\n",
      "           [False, False,  True]])\n",
      "    \n",
      "    For indexes, an ndarray of booleans is returned.\n",
      "    \n",
      "    >>> index = pd.DatetimeIndex([\"2017-07-05\", \"2017-07-06\", None,\n",
      "    ...                           \"2017-07-08\"])\n",
      "    >>> index\n",
      "    DatetimeIndex(['2017-07-05', '2017-07-06', 'NaT', '2017-07-08'],\n",
      "                  dtype='datetime64[ns]', freq=None)\n",
      "    >>> pd.isna(index)\n",
      "    array([False, False,  True, False])\n",
      "    \n",
      "    For Series and DataFrame, the same type is returned, containing booleans.\n",
      "    \n",
      "    >>> df = pd.DataFrame([['ant', 'bee', 'cat'], ['dog', None, 'fly']])\n",
      "    >>> df\n",
      "         0     1    2\n",
      "    0  ant   bee  cat\n",
      "    1  dog  None  fly\n",
      "    >>> pd.isna(df)\n",
      "           0      1      2\n",
      "    0  False  False  False\n",
      "    1  False   True  False\n",
      "    \n",
      "    >>> pd.isna(df[1])\n",
      "    0    False\n",
      "    1     True\n",
      "    Name: 1, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.isnull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "join(self, iterable, /)\n",
      "    Concatenate any number of strings.\n",
      "    \n",
      "    The string whose method is called is inserted in between each given string.\n",
      "    The result is returned as a new string.\n",
      "    \n",
      "    Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here\n",
    "def add_combine_type(row):\n",
    "    if pd.isnull(row[\"Type 2\"]):\n",
    "        return row[\"Type 1\"]\n",
    "    return \"\".join([row[\"Type 1\"], \"-\", row[\"Type 2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "      <th>Combo Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Grass-Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>Grass-Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>Grass-Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>Grass-Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.209302</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  A/D Ratio    Combo Type  \n",
       "0       65       65     45           1      False   1.000000  Grass-Poison  \n",
       "1       80       80     60           1      False   0.984127  Grass-Poison  \n",
       "2      100      100     80           1      False   0.987952  Grass-Poison  \n",
       "3      122      120     80           1      False   0.813008  Grass-Poison  \n",
       "4       60       50     65           1      False   1.209302          Fire  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon[\"Combo Type\"] = pokemon.apply(add_combine_type, axis=1)\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the pokemons whose `A/D Ratio` are among the top 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "      <th>Combo Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>386</td>\n",
       "      <td>DeoxysAttack Forme</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>50</td>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>9.000</td>\n",
       "      <td>Psychic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>318</td>\n",
       "      <td>Carvanha</td>\n",
       "      <td>Water</td>\n",
       "      <td>Dark</td>\n",
       "      <td>305</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>4.500</td>\n",
       "      <td>Water-Dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>BeedrillMega Beedrill</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Poison</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>150</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.750</td>\n",
       "      <td>Bug-Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>408</td>\n",
       "      <td>Cranidos</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3.125</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>319</td>\n",
       "      <td>Sharpedo</td>\n",
       "      <td>Water</td>\n",
       "      <td>Dark</td>\n",
       "      <td>460</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>40</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>3.000</td>\n",
       "      <td>Water-Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "429  386     DeoxysAttack Forme  Psychic     NaN    600  50     180       20   \n",
       "347  318               Carvanha    Water    Dark    305  45      90       20   \n",
       "19    15  BeedrillMega Beedrill      Bug  Poison    495  65     150       40   \n",
       "453  408               Cranidos     Rock     NaN    350  67     125       40   \n",
       "348  319               Sharpedo    Water    Dark    460  70     120       40   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  A/D Ratio  Combo Type  \n",
       "429      180       20    150           3       True      9.000     Psychic  \n",
       "347       65       20     65           3      False      4.500  Water-Dark  \n",
       "19        15       80    145           1      False      3.750  Bug-Poison  \n",
       "453       30       30     58           4      False      3.125        Rock  \n",
       "348       95       40     95           3      False      3.000  Water-Dark  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon.nlargest(5, \"A/D Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the aggregated Attack and Defense for each of the Combo Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pandas.core.groupby in pandas.core:\n",
      "\n",
      "NAME\n",
      "    pandas.core.groupby\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    base\n",
      "    categorical\n",
      "    generic\n",
      "    groupby\n",
      "    grouper\n",
      "    ops\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        pandas.core.groupby.grouper.Grouper\n",
      "    builtins.tuple(builtins.object)\n",
      "        pandas.core.groupby.generic.NamedAgg\n",
      "    pandas.core.groupby.groupby._GroupBy(pandas.core.base.PandasObject, pandas.core.base.SelectionMixin)\n",
      "        pandas.core.groupby.groupby.GroupBy\n",
      "            pandas.core.groupby.generic.DataFrameGroupBy\n",
      "            pandas.core.groupby.generic.SeriesGroupBy\n",
      "    \n",
      "    class DataFrameGroupBy(pandas.core.groupby.groupby.GroupBy)\n",
      "     |  DataFrameGroupBy(obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |  \n",
      "     |  Class for grouping and aggregating relational data.\n",
      "     |  \n",
      "     |  See aggregate, transform, and apply functions on this object.\n",
      "     |  \n",
      "     |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = groupby(obj, ...)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  obj : pandas object\n",
      "     |  axis : int, default 0\n",
      "     |  level : int, default None\n",
      "     |      Level of MultiIndex\n",
      "     |  groupings : list of Grouping objects\n",
      "     |      Most users should ignore this\n",
      "     |  exclusions : array-like, optional\n",
      "     |      List of columns to exclude\n",
      "     |  name : str\n",
      "     |      Most users should ignore this\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  **Attributes**\n",
      "     |  groups : dict\n",
      "     |      {group name -> group labels}\n",
      "     |  len(grouped) : int\n",
      "     |      Number of groups\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      "     |  some other brief notes about usage. When grouping by multiple groups, the\n",
      "     |  result index will be a MultiIndex (hierarchical) by default.\n",
      "     |  \n",
      "     |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      "     |  you can write code like:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = obj.groupby(keys, axis=axis)\n",
      "     |      for key, group in grouped:\n",
      "     |          # do something with the data\n",
      "     |  \n",
      "     |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      "     |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      "     |  method on each group, you can simply do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).std()\n",
      "     |  \n",
      "     |  rather than\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).aggregate(np.std)\n",
      "     |  \n",
      "     |  You can pass arguments to these \"wrapped\" functions, too.\n",
      "     |  \n",
      "     |  See the online documentation for full exposition on these topics and much\n",
      "     |  more\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DataFrameGroupBy\n",
      "     |      pandas.core.groupby.groupby.GroupBy\n",
      "     |      pandas.core.groupby.groupby._GroupBy\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  agg = aggregate(self, func=None, *args, **kwargs)\n",
      "     |  \n",
      "     |  aggregate(self, func=None, *args, **kwargs)\n",
      "     |      Aggregate using one or more operations over the specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function, str, list or dict\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      "     |      \n",
      "     |          Accepted combinations are:\n",
      "     |      \n",
      "     |          - function\n",
      "     |          - string function name\n",
      "     |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      "     |          - dict of axis labels -> functions, function names or list of such.\n",
      "     |      \n",
      "     |      *args\n",
      "     |          Positional arguments to pass to `func`.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments to pass to `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar, Series or DataFrame\n",
      "     |      \n",
      "     |          The return can be:\n",
      "     |      \n",
      "     |          * scalar : when Series.agg is called with single function\n",
      "     |          * Series : when DataFrame.agg is called with a single function\n",
      "     |          * DataFrame : when DataFrame.agg is called with several functions\n",
      "     |      \n",
      "     |          Return scalar, Series or DataFrame.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.DataFrame.groupby.apply\n",
      "     |      pandas.DataFrame.groupby.transform\n",
      "     |      pandas.DataFrame.aggregate\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      A passed user-defined-function will be passed a Series for evaluation.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 2],\n",
      "     |      ...                    'B': [1, 2, 3, 4],\n",
      "     |      ...                    'C': np.random.randn(4)})\n",
      "     |      \n",
      "     |      >>> df\n",
      "     |         A  B         C\n",
      "     |      0  1  1  0.362838\n",
      "     |      1  1  2  0.227877\n",
      "     |      2  2  3  1.267767\n",
      "     |      3  2  4 -0.562860\n",
      "     |      \n",
      "     |      The aggregation is for each column.\n",
      "     |      \n",
      "     |      >>> df.groupby('A').agg('min')\n",
      "     |         B         C\n",
      "     |      A\n",
      "     |      1  1  0.227877\n",
      "     |      2  3 -0.562860\n",
      "     |      \n",
      "     |      Multiple aggregations\n",
      "     |      \n",
      "     |      >>> df.groupby('A').agg(['min', 'max'])\n",
      "     |          B             C\n",
      "     |        min max       min       max\n",
      "     |      A\n",
      "     |      1   1   2  0.227877  0.362838\n",
      "     |      2   3   4 -0.562860  1.267767\n",
      "     |      \n",
      "     |      Select a column for aggregation\n",
      "     |      \n",
      "     |      >>> df.groupby('A').B.agg(['min', 'max'])\n",
      "     |         min  max\n",
      "     |      A\n",
      "     |      1    1    2\n",
      "     |      2    3    4\n",
      "     |      \n",
      "     |      Different aggregations per column\n",
      "     |      \n",
      "     |      >>> df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'})\n",
      "     |          B             C\n",
      "     |        min max       sum\n",
      "     |      A\n",
      "     |      1   1   2  0.590716\n",
      "     |      2   3   4  0.704907\n",
      "     |      \n",
      "     |      To control the output names with different aggregations per column,\n",
      "     |      pandas supports \"named aggregation\"\n",
      "     |      \n",
      "     |      >>> df.groupby(\"A\").agg(\n",
      "     |      ...     b_min=pd.NamedAgg(column=\"B\", aggfunc=\"min\"),\n",
      "     |      ...     c_sum=pd.NamedAgg(column=\"C\", aggfunc=\"sum\"))\n",
      "     |         b_min     c_sum\n",
      "     |      A\n",
      "     |      1      1 -1.956929\n",
      "     |      2      3 -0.322183\n",
      "     |      \n",
      "     |      - The keywords are the *output* column names\n",
      "     |      - The values are tuples whose first element is the column to select\n",
      "     |        and the second element is the aggregation to apply to that column.\n",
      "     |        Pandas provides the ``pandas.NamedAgg`` namedtuple with the fields\n",
      "     |        ``['column', 'aggfunc']`` to make it clearer what the arguments are.\n",
      "     |        As usual, the aggregation can be a callable or a string alias.\n",
      "     |      \n",
      "     |      See :ref:`groupby.aggregate.named` for more.\n",
      "     |  \n",
      "     |  boxplot = boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharex=False, sharey=True, backend=None, **kwargs)\n",
      "     |      Make box plots from DataFrameGroupBy data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      grouped : Grouped DataFrame\n",
      "     |      subplots : bool\n",
      "     |          * ``False`` - no subplots will be used\n",
      "     |          * ``True`` - create a subplot for each group.\n",
      "     |      \n",
      "     |      column : column name or list of names, or vector\n",
      "     |          Can be any valid input to groupby.\n",
      "     |      fontsize : int or str\n",
      "     |      rot : label rotation angle\n",
      "     |      grid : Setting this to True will show the grid\n",
      "     |      ax : Matplotlib axis object, default None\n",
      "     |      figsize : A tuple (width, height) in inches\n",
      "     |      layout : tuple (optional)\n",
      "     |          The layout of the plot: (rows, columns).\n",
      "     |      sharex : bool, default False\n",
      "     |          Whether x-axes will be shared among subplots.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.23.1\n",
      "     |      sharey : bool, default True\n",
      "     |          Whether y-axes will be shared among subplots.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.23.1\n",
      "     |      backend : str, default None\n",
      "     |          Backend to use instead of the backend specified in the option\n",
      "     |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      "     |          specify the ``plotting.backend`` for the whole session, set\n",
      "     |          ``pd.options.plotting.backend``.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.0.0\n",
      "     |      \n",
      "     |      **kwargs\n",
      "     |          All other plotting keyword arguments to be passed to\n",
      "     |          matplotlib's boxplot function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict of key/value = group key/DataFrame.boxplot return value\n",
      "     |      or DataFrame.boxplot return value in case subplots=figures=False\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import itertools\n",
      "     |      >>> tuples = [t for t in itertools.product(range(1000), range(4))]\n",
      "     |      >>> index = pd.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])\n",
      "     |      >>> data = np.random.randn(len(index),4)\n",
      "     |      >>> df = pd.DataFrame(data, columns=list('ABCD'), index=index)\n",
      "     |      >>>\n",
      "     |      >>> grouped = df.groupby(level='lvl1')\n",
      "     |      >>> boxplot_frame_groupby(grouped)\n",
      "     |      >>>\n",
      "     |      >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)\n",
      "     |      >>> boxplot_frame_groupby(grouped, subplots=False)\n",
      "     |  \n",
      "     |  count(self)\n",
      "     |      Compute count of group, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          Count of values within each group.\n",
      "     |  \n",
      "     |  filter(self, func, dropna=True, *args, **kwargs)\n",
      "     |      Return a copy of a DataFrame excluding elements from groups that\n",
      "     |      do not satisfy the boolean criterion specified by func.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      f : function\n",
      "     |          Function to apply to each subframe. Should return True or False.\n",
      "     |      dropna : Drop groups that do not pass the filter. True by default;\n",
      "     |          If False, groups that evaluate False are filled with NaNs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filtered : DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Each subframe is endowed the attribute 'name' in case you need to know\n",
      "     |      which group you are working on.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      "     |      ...                           'foo', 'bar'],\n",
      "     |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      "     |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      "     |      >>> grouped = df.groupby('A')\n",
      "     |      >>> grouped.filter(lambda x: x['B'].mean() > 3.)\n",
      "     |           A  B    C\n",
      "     |      1  bar  2  5.0\n",
      "     |      3  bar  4  1.0\n",
      "     |      5  bar  6  9.0\n",
      "     |  \n",
      "     |  nunique(self, dropna: bool = True)\n",
      "     |      Return DataFrame with number of distinct observations per group for\n",
      "     |      each column.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dropna : bool, default True\n",
      "     |          Don't include NaN in the counts.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      nunique: DataFrame\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam',\n",
      "     |      ...                           'ham', 'ham'],\n",
      "     |      ...                    'value1': [1, 5, 5, 2, 5, 5],\n",
      "     |      ...                    'value2': list('abbaxy')})\n",
      "     |      >>> df\n",
      "     |           id  value1 value2\n",
      "     |      0  spam       1      a\n",
      "     |      1   egg       5      b\n",
      "     |      2   egg       5      b\n",
      "     |      3  spam       2      a\n",
      "     |      4   ham       5      x\n",
      "     |      5   ham       5      y\n",
      "     |      \n",
      "     |      >>> df.groupby('id').nunique()\n",
      "     |          id  value1  value2\n",
      "     |      id\n",
      "     |      egg    1       1       1\n",
      "     |      ham    1       1       2\n",
      "     |      spam   1       2       1\n",
      "     |      \n",
      "     |      Check for rows with the same id but conflicting values:\n",
      "     |      \n",
      "     |      >>> df.groupby('id').filter(lambda g: (g.nunique() > 1).any())\n",
      "     |           id  value1 value2\n",
      "     |      0  spam       1      a\n",
      "     |      3  spam       2      a\n",
      "     |      4   ham       5      x\n",
      "     |      5   ham       5      y\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed DataFrame on each group and\n",
      "     |      return a DataFrame having the same indexes as the original object\n",
      "     |      filled with the transformed values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      f : function\n",
      "     |          Function to apply to each group\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      aggregate, transform\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Each group is endowed the attribute 'name' in case you need to know\n",
      "     |      which group you are working on.\n",
      "     |      \n",
      "     |      The current implementation imposes three requirements on f:\n",
      "     |      \n",
      "     |      * f must return a value that either has the same shape as the input\n",
      "     |        subframe or can be broadcast to the shape of the input subframe.\n",
      "     |        For example, if `f` returns a scalar it will be broadcast to have the\n",
      "     |        same shape as the input subframe.\n",
      "     |      * if this is a DataFrame, f must support application column-by-column\n",
      "     |        in the subframe. If f also supports application to the entire subframe,\n",
      "     |        then a fast path is used starting from the second chunk.\n",
      "     |      * f must not mutate groups. Mutation is not supported and may\n",
      "     |        produce unexpected results.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      # Same shape\n",
      "     |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      "     |      ...                           'foo', 'bar'],\n",
      "     |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      "     |      ...                          'two', 'two'],\n",
      "     |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      "     |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      "     |      >>> grouped = df.groupby('A')\n",
      "     |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                C         D\n",
      "     |      0 -1.154701 -0.577350\n",
      "     |      1  0.577350  0.000000\n",
      "     |      2  0.577350  1.154701\n",
      "     |      3 -1.154701 -1.000000\n",
      "     |      4  0.577350 -0.577350\n",
      "     |      5  0.577350  1.000000\n",
      "     |      \n",
      "     |      # Broadcastable\n",
      "     |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      "     |         C    D\n",
      "     |      0  4  6.0\n",
      "     |      1  3  8.0\n",
      "     |      2  4  6.0\n",
      "     |      3  3  8.0\n",
      "     |      4  4  6.0\n",
      "     |      5  3  8.0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  corr\n",
      "     |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      "     |          Method of correlation:\n",
      "     |      \n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |          * callable: callable with input two 1d ndarrays\n",
      "     |              and returning a float. Note that the returned matrix from corr\n",
      "     |              will have 1 along the diagonals and will be symmetric\n",
      "     |              regardless of the callable's behavior.\n",
      "     |      \n",
      "     |              .. versionadded:: 0.24.0\n",
      "     |      \n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result. Currently only available for Pearson\n",
      "     |          and Spearman correlation.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          Correlation matrix.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.corrwith\n",
      "     |      Series.corr\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> def histogram_intersection(a, b):\n",
      "     |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      "     |      ...     return v\n",
      "     |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      "     |      ...                   columns=['dogs', 'cats'])\n",
      "     |      >>> df.corr(method=histogram_intersection)\n",
      "     |            dogs  cats\n",
      "     |      dogs   1.0   0.3\n",
      "     |      cats   0.3   1.0\n",
      "     |  \n",
      "     |  corrwith\n",
      "     |      Compute pairwise correlation.\n",
      "     |      \n",
      "     |      Pairwise correlation is computed between rows or columns of\n",
      "     |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      "     |      are first aligned along both axes before computing the\n",
      "     |      correlations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : DataFrame, Series\n",
      "     |          Object with which to compute correlations.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n",
      "     |          row-wise.\n",
      "     |      drop : bool, default False\n",
      "     |          Drop missing indices from result.\n",
      "     |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      "     |          Method of correlation:\n",
      "     |      \n",
      "     |          * pearson : standard correlation coefficient\n",
      "     |          * kendall : Kendall Tau correlation coefficient\n",
      "     |          * spearman : Spearman rank correlation\n",
      "     |          * callable: callable with input two 1d ndarrays\n",
      "     |              and returning a float.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.24.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Pairwise correlations.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.corr\n",
      "     |  \n",
      "     |  cov\n",
      "     |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      "     |      \n",
      "     |      Compute the pairwise covariance among the series of a DataFrame.\n",
      "     |      The returned data frame is the `covariance matrix\n",
      "     |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      "     |      of the DataFrame.\n",
      "     |      \n",
      "     |      Both NA and null values are automatically excluded from the\n",
      "     |      calculation. (See the note below about bias from missing values.)\n",
      "     |      A threshold can be set for the minimum number of\n",
      "     |      observations for each value created. Comparisons with observations\n",
      "     |      below this threshold will be returned as ``NaN``.\n",
      "     |      \n",
      "     |      This method is generally used for the analysis of time series data to\n",
      "     |      understand the relationship between different measures\n",
      "     |      across time.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations required per pair of columns\n",
      "     |          to have a valid result.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          The covariance matrix of the series of the DataFrame.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.cov : Compute covariance with another Series.\n",
      "     |      core.window.EWM.cov: Exponential weighted sample covariance.\n",
      "     |      core.window.Expanding.cov : Expanding sample covariance.\n",
      "     |      core.window.Rolling.cov : Rolling sample covariance.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Returns the covariance matrix of the DataFrame's time series.\n",
      "     |      The covariance is normalized by N-1.\n",
      "     |      \n",
      "     |      For DataFrames that have Series that are missing data (assuming that\n",
      "     |      data is `missing at random\n",
      "     |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      "     |      the returned covariance matrix will be an unbiased estimate\n",
      "     |      of the variance and covariance between the member Series.\n",
      "     |      \n",
      "     |      However, for many applications this estimate may not be acceptable\n",
      "     |      because the estimate covariance matrix is not guaranteed to be positive\n",
      "     |      semi-definite. This could lead to estimate correlations having\n",
      "     |      absolute values which are greater than one, and/or a non-invertible\n",
      "     |      covariance matrix. See `Estimation of covariance matrices\n",
      "     |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      "     |      matrices>`__ for more details.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      "     |      ...                   columns=['dogs', 'cats'])\n",
      "     |      >>> df.cov()\n",
      "     |                dogs      cats\n",
      "     |      dogs  0.666667 -1.000000\n",
      "     |      cats -1.000000  1.666667\n",
      "     |      \n",
      "     |      >>> np.random.seed(42)\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      "     |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      "     |      >>> df.cov()\n",
      "     |                a         b         c         d         e\n",
      "     |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      "     |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      "     |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      "     |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      "     |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      "     |      \n",
      "     |      **Minimum number of periods**\n",
      "     |      \n",
      "     |      This method also supports an optional ``min_periods`` keyword\n",
      "     |      that specifies the required minimum number of non-NA observations for\n",
      "     |      each column pair in order to have a valid result:\n",
      "     |      \n",
      "     |      >>> np.random.seed(42)\n",
      "     |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      "     |      ...                   columns=['a', 'b', 'c'])\n",
      "     |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      "     |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      "     |      >>> df.cov(min_periods=12)\n",
      "     |                a         b         c\n",
      "     |      a  0.316741       NaN -0.150812\n",
      "     |      b       NaN  1.248003  0.191417\n",
      "     |      c -0.150812  0.191417  0.895202\n",
      "     |  \n",
      "     |  diff\n",
      "     |      First discrete difference of element.\n",
      "     |      \n",
      "     |      Calculates the difference of a DataFrame element compared with another\n",
      "     |      element in the DataFrame (default is the element in the same column\n",
      "     |      of the previous row).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for calculating difference, accepts negative\n",
      "     |          values.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          Take difference over rows (0) or columns (1).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.diff: First discrete difference for a Series.\n",
      "     |      DataFrame.pct_change: Percent change over given number of periods.\n",
      "     |      DataFrame.shift: Shift index by desired number of periods with an\n",
      "     |          optional time freq.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      "     |      :meth:`operator.sub`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Difference with previous row\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      "     |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      "     |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      "     |      >>> df\n",
      "     |         a  b   c\n",
      "     |      0  1  1   1\n",
      "     |      1  2  1   4\n",
      "     |      2  3  2   9\n",
      "     |      3  4  3  16\n",
      "     |      4  5  5  25\n",
      "     |      5  6  8  36\n",
      "     |      \n",
      "     |      >>> df.diff()\n",
      "     |           a    b     c\n",
      "     |      0  NaN  NaN   NaN\n",
      "     |      1  1.0  0.0   3.0\n",
      "     |      2  1.0  1.0   5.0\n",
      "     |      3  1.0  1.0   7.0\n",
      "     |      4  1.0  2.0   9.0\n",
      "     |      5  1.0  3.0  11.0\n",
      "     |      \n",
      "     |      Difference with previous column\n",
      "     |      \n",
      "     |      >>> df.diff(axis=1)\n",
      "     |          a    b     c\n",
      "     |      0 NaN  0.0   0.0\n",
      "     |      1 NaN -1.0   3.0\n",
      "     |      2 NaN -1.0   7.0\n",
      "     |      3 NaN -1.0  13.0\n",
      "     |      4 NaN  0.0  20.0\n",
      "     |      5 NaN  2.0  28.0\n",
      "     |      \n",
      "     |      Difference with 3rd previous row\n",
      "     |      \n",
      "     |      >>> df.diff(periods=3)\n",
      "     |           a    b     c\n",
      "     |      0  NaN  NaN   NaN\n",
      "     |      1  NaN  NaN   NaN\n",
      "     |      2  NaN  NaN   NaN\n",
      "     |      3  3.0  2.0  15.0\n",
      "     |      4  3.0  4.0  21.0\n",
      "     |      5  3.0  6.0  27.0\n",
      "     |      \n",
      "     |      Difference with following row\n",
      "     |      \n",
      "     |      >>> df.diff(periods=-1)\n",
      "     |           a    b     c\n",
      "     |      0 -1.0  0.0  -3.0\n",
      "     |      1 -1.0 -1.0  -5.0\n",
      "     |      2 -1.0 -1.0  -7.0\n",
      "     |      3 -1.0 -2.0  -9.0\n",
      "     |      4 -1.0 -3.0 -11.0\n",
      "     |      5  NaN  NaN   NaN\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      Return the dtypes in the DataFrame.\n",
      "     |      \n",
      "     |      This returns a Series with the data type of each column.\n",
      "     |      The result's index is the original DataFrame's columns. Columns\n",
      "     |      with mixed types are stored with the ``object`` dtype. See\n",
      "     |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pandas.Series\n",
      "     |          The data type of each column.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'float': [1.0],\n",
      "     |      ...                    'int': [1],\n",
      "     |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      "     |      ...                    'string': ['foo']})\n",
      "     |      >>> df.dtypes\n",
      "     |      float              float64\n",
      "     |      int                  int64\n",
      "     |      datetime    datetime64[ns]\n",
      "     |      string              object\n",
      "     |      dtype: object\n",
      "     |  \n",
      "     |  fillna\n",
      "     |      Fill NA/NaN values using the specified method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      "     |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use next valid observation to fill gap.\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}\n",
      "     |          Axis along which to fill missing values.\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, fill in-place. Note: this will modify any\n",
      "     |          other views on this object (e.g., a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          A dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame or None\n",
      "     |          Object with missing values filled or None if ``inplace=True``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      interpolate : Fill NaN values using interpolation.\n",
      "     |      reindex : Conform object to new index.\n",
      "     |      asfreq : Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                   columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  hist\n",
      "     |      Make a histogram of the DataFrame's.\n",
      "     |      \n",
      "     |      A `histogram`_ is a representation of the distribution of data.\n",
      "     |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      "     |      the DataFrame, resulting in one histogram per column.\n",
      "     |      \n",
      "     |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : DataFrame\n",
      "     |          The pandas object holding the data.\n",
      "     |      column : str or sequence\n",
      "     |          If passed, will be used to limit data to a subset of columns.\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups.\n",
      "     |      grid : bool, default True\n",
      "     |          Whether to show axis grid lines.\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size.\n",
      "     |      xrot : float, default None\n",
      "     |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      "     |          x labels rotated 90 degrees clockwise.\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size.\n",
      "     |      yrot : float, default None\n",
      "     |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      "     |          y labels rotated 90 degrees clockwise.\n",
      "     |      ax : Matplotlib axes object, default None\n",
      "     |          The axes to plot the histogram on.\n",
      "     |      sharex : bool, default True if ax is None else False\n",
      "     |          In case subplots=True, share x axis and set some x axis labels to\n",
      "     |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      "     |          is passed in.\n",
      "     |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      "     |          labels for all subplots in a figure.\n",
      "     |      sharey : bool, default False\n",
      "     |          In case subplots=True, share y axis and set some y axis labels to\n",
      "     |          invisible.\n",
      "     |      figsize : tuple\n",
      "     |          The size in inches of the figure to create. Uses the value in\n",
      "     |          `matplotlib.rcParams` by default.\n",
      "     |      layout : tuple, optional\n",
      "     |          Tuple of (rows, columns) for the layout of the histograms.\n",
      "     |      bins : int or sequence, default 10\n",
      "     |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      "     |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      "     |          bin edges, including left edge of first bin and right edge of last\n",
      "     |          bin. In this case, bins is returned unmodified.\n",
      "     |      backend : str, default None\n",
      "     |          Backend to use instead of the backend specified in the option\n",
      "     |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      "     |          specify the ``plotting.backend`` for the whole session, set\n",
      "     |          ``pd.options.plotting.backend``.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.0.0\n",
      "     |      \n",
      "     |      **kwargs\n",
      "     |          All other plotting keyword arguments to be passed to\n",
      "     |          :meth:`matplotlib.pyplot.hist`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      .. plot::\n",
      "     |          :context: close-figs\n",
      "     |      \n",
      "     |          This example draws a histogram based on the length and width of\n",
      "     |          some animals, displayed in three bins\n",
      "     |      \n",
      "     |          >>> df = pd.DataFrame({\n",
      "     |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      "     |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      "     |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      "     |          >>> hist = df.hist(bins=3)\n",
      "     |  \n",
      "     |  idxmax\n",
      "     |      Return index of first occurrence of maximum over requested axis.\n",
      "     |      \n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Indexes of maxima along the specified axis.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmax\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      "     |  \n",
      "     |  idxmin\n",
      "     |      Return index of first occurrence of minimum over requested axis.\n",
      "     |      \n",
      "     |      NA/null values are excluded.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "     |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      "     |          will be NA.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Indexes of minima along the specified axis.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          * If the row/column is empty\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.idxmin\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      "     |  \n",
      "     |  mad\n",
      "     |      Return the mean absolute deviation of the values for the requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |          Axis for the function to be applied on.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series.\n",
      "     |      numeric_only : bool, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to be passed to the function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  skew\n",
      "     |      Return unbiased skew over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0), columns (1)}\n",
      "     |          Axis for the function to be applied on.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a Series.\n",
      "     |      numeric_only : bool, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to be passed to the function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame (if level specified)\n",
      "     |  \n",
      "     |  take\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      "     |          The axis on which to select elements. ``0`` means that we are\n",
      "     |          selecting rows, ``1`` means that we are selecting columns.\n",
      "     |      is_copy : bool\n",
      "     |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      "     |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      "     |          ``take`` always returns a copy, and the keyword is therefore\n",
      "     |          deprecated.\n",
      "     |      \n",
      "     |          .. deprecated:: 1.0.0\n",
      "     |      **kwargs\n",
      "     |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      "     |          output.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : same type as caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      "     |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      "     |      numpy.take : Take elements from an array along an axis.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      "     |      ...                    ('parrot', 'bird', 24.0),\n",
      "     |      ...                    ('lion', 'mammal', 80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=['name', 'class', 'max_speed'],\n",
      "     |      ...                   index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |  \n",
      "     |  tshift\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative.\n",
      "     |      freq : DateOffset, timedelta, or str, default None\n",
      "     |          Increment to use from the tseries module\n",
      "     |          or time rule expressed as a string (e.g. 'EOM').\n",
      "     |      axis : {0 or index, 1 or columns, None}, default 0\n",
      "     |          Corresponds to the axis that contains the Index.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : Series/DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      "     |  \n",
      "     |  all(self, skipna: bool = True)\n",
      "     |      Return True if all values in the group are truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  any(self, skipna: bool = True)\n",
      "     |      Return True if any value in the group is truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  backfill(self, limit=None)\n",
      "     |      Backward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.backfill\n",
      "     |      DataFrame.backfill\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  bfill = backfill(self, limit=None)\n",
      "     |  \n",
      "     |  cumcount(self, ascending: bool = True)\n",
      "     |      Number each item in each group from 0 to the length of that group - 1.\n",
      "     |      \n",
      "     |      Essentially this is equivalent to\n",
      "     |      \n",
      "     |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from length of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Sequence number of each element within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .ngroup : Number the groups themselves.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      "     |      ...                   columns=['A'])\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').cumcount()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    0\n",
      "     |      4    1\n",
      "     |      5    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').cumcount(ascending=False)\n",
      "     |      0    3\n",
      "     |      1    2\n",
      "     |      2    1\n",
      "     |      3    1\n",
      "     |      4    0\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  cummax(self, axis=0, **kwargs)\n",
      "     |      Cumulative max for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cummin(self, axis=0, **kwargs)\n",
      "     |      Cumulative min for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumprod(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative product for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumsum(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative sum for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  describe(self, **kwargs)\n",
      "     |      Generate descriptive statistics.\n",
      "     |      \n",
      "     |      Descriptive statistics include those that summarize the central\n",
      "     |      tendency, dispersion and shape of a\n",
      "     |      dataset's distribution, excluding ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Summary statistics of the Series or Dataframe provided.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count: Count number of non-NA/null observations.\n",
      "     |      DataFrame.max: Maximum of the values in the object.\n",
      "     |      DataFrame.min: Minimum of the values in the object.\n",
      "     |      DataFrame.mean: Mean of the values.\n",
      "     |      DataFrame.std: Standard deviation of the observations.\n",
      "     |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      "     |          columns based on their dtype.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      "     |      ...                    'numeric': [1, 2, 3],\n",
      "     |      ...                    'object': ['a', 'b', 'c']\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |             categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |  \n",
      "     |  expanding(self, *args, **kwargs)\n",
      "     |      Return an expanding grouper, providing expanding\n",
      "     |      functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ffill = pad(self, limit=None)\n",
      "     |  \n",
      "     |  first(self, **kwargs)\n",
      "     |      Compute first of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed first of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return first n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').head(1)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      2  5  6\n",
      "     |      >>> df.groupby('A').head(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  last(self, **kwargs)\n",
      "     |      Compute last of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed last of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  max(self, **kwargs)\n",
      "     |      Compute max of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed max of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  mean(self, *args, **kwargs)\n",
      "     |      Compute mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pandas.Series or pandas.DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      "     |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of the remaining columns in\n",
      "     |      each group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A').mean()\n",
      "     |           B         C\n",
      "     |      A\n",
      "     |      1  3.0  1.333333\n",
      "     |      2  4.0  1.500000\n",
      "     |      \n",
      "     |      Groupby two columns and return the mean of the remaining column.\n",
      "     |      \n",
      "     |      >>> df.groupby(['A', 'B']).mean()\n",
      "     |             C\n",
      "     |      A B\n",
      "     |      1 2.0  2\n",
      "     |        4.0  1\n",
      "     |      2 3.0  1\n",
      "     |        5.0  2\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of only particular column in\n",
      "     |      the group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A')['B'].mean()\n",
      "     |      A\n",
      "     |      1    3.0\n",
      "     |      2    4.0\n",
      "     |      Name: B, dtype: float64\n",
      "     |  \n",
      "     |  median(self, **kwargs)\n",
      "     |      Compute median of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Median of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  min(self, **kwargs)\n",
      "     |      Compute min of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed min of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  ngroup(self, ascending: bool = True)\n",
      "     |      Number each group from 0 to the number of groups - 1.\n",
      "     |      \n",
      "     |      This is the enumerative complement of cumcount.  Note that the\n",
      "     |      numbers given to the groups match the order in which the groups\n",
      "     |      would be seen when iterating over the groupby object, not the\n",
      "     |      order they are first observed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from number of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Unique numbers for each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .cumcount : Number the rows in each group.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    0\n",
      "     |      3    1\n",
      "     |      4    1\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').ngroup(ascending=False)\n",
      "     |      0    1\n",
      "     |      1    1\n",
      "     |      2    1\n",
      "     |      3    0\n",
      "     |      4    0\n",
      "     |      5    1\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    1\n",
      "     |      3    3\n",
      "     |      4    2\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  nth(self, n: Union[int, List[int]], dropna: Union[str, NoneType] = None) -> pandas.core.frame.DataFrame\n",
      "     |      Take the nth row from each group if n is an int, or a subset of rows\n",
      "     |      if n is a list of ints.\n",
      "     |      \n",
      "     |      If dropna, will take the nth non-null row, dropna is either\n",
      "     |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      "     |      before the groupby.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or list of ints\n",
      "     |          A single nth value for the row or a list of nth values.\n",
      "     |      dropna : None or str, optional\n",
      "     |          Apply the specified dropna operation before counting which row is\n",
      "     |          the nth row. Needs to be None, 'any' or 'all'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          N-th value within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      "     |      >>> g = df.groupby('A')\n",
      "     |      >>> g.nth(0)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      2  3.0\n",
      "     |      >>> g.nth(1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth(-1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  4.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth([0, 1])\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      2  5.0\n",
      "     |      \n",
      "     |      Specifying `dropna` allows count ignoring ``NaN``\n",
      "     |      \n",
      "     |      >>> g.nth(0, dropna='any')\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      \n",
      "     |      NaNs denote group exhausted when using dropna\n",
      "     |      \n",
      "     |      >>> g.nth(3, dropna='any')\n",
      "     |          B\n",
      "     |      A\n",
      "     |      1 NaN\n",
      "     |      2 NaN\n",
      "     |      \n",
      "     |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      "     |      \n",
      "     |      >>> df.groupby('A', as_index=False).nth(1)\n",
      "     |         A    B\n",
      "     |      1  1  2.0\n",
      "     |      4  2  5.0\n",
      "     |  \n",
      "     |  ohlc(self) -> pandas.core.frame.DataFrame\n",
      "     |      Compute sum of values, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          Open, high, low and close values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  pad(self, limit=None)\n",
      "     |      Forward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pad\n",
      "     |      DataFrame.pad\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)\n",
      "     |      Calculate pct_change of each value to previous entry in group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Percentage changes within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  prod(self, **kwargs)\n",
      "     |      Compute prod of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed prod of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, interpolation: str = 'linear')\n",
      "     |      Return group values at the given quantile, a la numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          Method to use when the desired quantile falls between two points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Return type determined by caller of GroupBy object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.quantile : Similar method for Series.\n",
      "     |      DataFrame.quantile : Similar method for DataFrame.\n",
      "     |      numpy.percentile : NumPy method to compute qth percentile.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([\n",
      "     |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      "     |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      "     |      ... ], columns=['key', 'val'])\n",
      "     |      >>> df.groupby('key').quantile()\n",
      "     |          val\n",
      "     |      key\n",
      "     |      a    2.0\n",
      "     |      b    3.0\n",
      "     |  \n",
      "     |  rank(self, method: str = 'average', ascending: bool = True, na_option: str = 'keep', pct: bool = False, axis: int = 0)\n",
      "     |      Provide the rank of values within each group.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      "     |          * average: average rank of group.\n",
      "     |          * min: lowest rank in group.\n",
      "     |          * max: highest rank in group.\n",
      "     |          * first: ranks assigned in order they appear in the array.\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      "     |      ascending : bool, default True\n",
      "     |          False for ranks by high (1) to low (N).\n",
      "     |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      "     |          * keep: leave NA values where they are.\n",
      "     |          * top: smallest rank if ascending.\n",
      "     |          * bottom: smallest rank if descending.\n",
      "     |      pct : bool, default False\n",
      "     |          Compute percentage rank of data within each group.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis of the object over which to compute the rank.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame with ranking of values within each group\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  resample(self, rule, *args, **kwargs)\n",
      "     |      Provide resampling when using a TimeGrouper.\n",
      "     |      \n",
      "     |      Given a grouper, the function resamples it according to a string\n",
      "     |      \"string\" -> \"frequency\".\n",
      "     |      \n",
      "     |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      "     |      documentation for more details.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : str or DateOffset\n",
      "     |          The offset string or object representing target grouper conversion.\n",
      "     |      *args, **kwargs\n",
      "     |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      "     |          `on`, and other arguments of `TimeGrouper`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Grouper\n",
      "     |          Return a new grouper with our resampler appended.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Grouper : Specify a frequency to resample with when\n",
      "     |          grouping by a key.\n",
      "     |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      "     |          time series.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      "     |      ...                   index=idx,\n",
      "     |      ...                   columns=['a', 'b'])\n",
      "     |      >>> df.iloc[2, 0] = 5\n",
      "     |      >>> df\n",
      "     |                          a  b\n",
      "     |      2000-01-01 00:00:00  0  1\n",
      "     |      2000-01-01 00:01:00  0  1\n",
      "     |      2000-01-01 00:02:00  5  1\n",
      "     |      2000-01-01 00:03:00  0  1\n",
      "     |      \n",
      "     |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      "     |      the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  2\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('30S').sum()\n",
      "     |                          a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:00:30  0  0\n",
      "     |          2000-01-01 00:01:00  0  1\n",
      "     |          2000-01-01 00:01:30  0  0\n",
      "     |          2000-01-01 00:02:00  0  0\n",
      "     |          2000-01-01 00:02:30  0  0\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:02:00  5  1\n",
      "     |      \n",
      "     |      Resample by month. Values are assigned to the month of the period.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('M').sum()\n",
      "     |                  a  b\n",
      "     |      a\n",
      "     |      0   2000-01-31  0  3\n",
      "     |      5   2000-01-31  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   1999-12-31 23:57:00  0  1\n",
      "     |          2000-01-01 00:00:00  0  2\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and close the right side of\n",
      "     |      the bin interval, but label each bin using the right edge instead of\n",
      "     |      the left.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:03:00  0  2\n",
      "     |      5   2000-01-01 00:03:00  5  1\n",
      "     |      \n",
      "     |      Add an offset of twenty seconds.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      "     |                             a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:20  0  2\n",
      "     |          2000-01-01 00:03:20  0  1\n",
      "     |      5   2000-01-01 00:00:20  5  1\n",
      "     |  \n",
      "     |  rolling(self, *args, **kwargs)\n",
      "     |      Return a rolling grouper, providing rolling functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sem(self, ddof: int = 1)\n",
      "     |      Compute standard error of the mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard error of the mean of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      "     |      Shift each group by periods observations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Number of periods to shift.\n",
      "     |      freq : frequency string\n",
      "     |      axis : axis to shift, default 0\n",
      "     |      fill_value : optional\n",
      "     |      \n",
      "     |          .. versionadded:: 0.24.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object shifted within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  size(self)\n",
      "     |      Compute group sizes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Number of rows in each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  std(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute standard deviation of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard deviation of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sum(self, **kwargs)\n",
      "     |      Compute sum of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed sum of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return last n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').tail(1)\n",
      "     |         A  B\n",
      "     |      1  a  2\n",
      "     |      3  b  2\n",
      "     |      >>> df.groupby('A').tail(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  var(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute variance of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Variance of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  __getattr__(self, attr: str)\n",
      "     |  \n",
      "     |  __init__(self, obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Groupby iterator.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Generator yielding sequence of (name, subsetted object)\n",
      "     |      for each group\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return a string representation for a particular object.\n",
      "     |  \n",
      "     |  apply(self, func, *args, **kwargs)\n",
      "     |      Apply function `func`  group-wise and combine the results together.\n",
      "     |      \n",
      "     |      The function passed to `apply` must take a dataframe as its first\n",
      "     |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      "     |      then take care of combining the results back together into a single\n",
      "     |      dataframe or series. `apply` is therefore a highly flexible\n",
      "     |      grouping method.\n",
      "     |      \n",
      "     |      While `apply` is a very flexible method, its downside is that\n",
      "     |      using it can be quite a bit slower than using more specific methods\n",
      "     |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      "     |      be much faster than using `apply` for their specific purposes, so try to\n",
      "     |      use them before reaching for `apply`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable\n",
      "     |          A callable that takes a dataframe as its first argument, and\n",
      "     |          returns a dataframe, a series or a scalar. In addition the\n",
      "     |          callable may take positional and keyword arguments.\n",
      "     |      args, kwargs : tuple and dict\n",
      "     |          Optional positional and keyword arguments to pass to `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pipe : Apply function to the full GroupBy object instead of to each\n",
      "     |          group.\n",
      "     |      aggregate : Apply aggregate function to the GroupBy object.\n",
      "     |      transform : Apply function column-by-column to the GroupBy object.\n",
      "     |      Series.apply : Apply a function to a Series.\n",
      "     |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      "     |  \n",
      "     |  get_group(self, name, obj=None)\n",
      "     |      Construct DataFrame from group with provided name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : object\n",
      "     |          The name of the group to get as a DataFrame.\n",
      "     |      obj : DataFrame, default None\n",
      "     |          The DataFrame to take the DataFrame out of.  If\n",
      "     |          it is None, the object groupby was called on will\n",
      "     |          be used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group : same type as obj\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply a function `func` with arguments to this GroupBy object and return\n",
      "     |      the function's result.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Use `.pipe` when you want to improve readability by chaining together\n",
      "     |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      "     |      Instead of writing\n",
      "     |      \n",
      "     |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.groupby('group')\n",
      "     |      ...    .pipe(f)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(h, arg2=b, arg3=c))\n",
      "     |      \n",
      "     |      which is much more readable.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable or tuple of (callable, string)\n",
      "     |          Function to apply to this GroupBy object or, alternatively,\n",
      "     |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      "     |          string indicating the keyword of `callable` that expects the\n",
      "     |          GroupBy object.\n",
      "     |      args : iterable, optional\n",
      "     |             Positional arguments passed into `func`.\n",
      "     |      kwargs : dict, optional\n",
      "     |               A dictionary of keyword arguments passed into `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of `func`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pipe : Apply a function with arguments to a series.\n",
      "     |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      "     |      apply : Apply function to each group instead of to the\n",
      "     |          full GroupBy object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See more `here\n",
      "     |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  1\n",
      "     |      1  b  2\n",
      "     |      2  a  3\n",
      "     |      3  b  4\n",
      "     |      \n",
      "     |      To get the difference between each groups maximum and minimum value in one\n",
      "     |      pass, you can do\n",
      "     |      \n",
      "     |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      "     |         B\n",
      "     |      A\n",
      "     |      a  2\n",
      "     |      b  2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  groups\n",
      "     |      Dict {group name -> group labels}.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Dict {group name -> group indices}.\n",
      "     |  \n",
      "     |  ngroups\n",
      "     |  \n",
      "     |  plot\n",
      "     |      Class implementing the .plot attribute for groupby objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  __annotations__ = {'_apply_whitelist': typing.FrozenSet[str]}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      "     |  \n",
      "     |  ndim\n",
      "    \n",
      "    class GroupBy(_GroupBy)\n",
      "     |  GroupBy(obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |  \n",
      "     |  Class for grouping and aggregating relational data.\n",
      "     |  \n",
      "     |  See aggregate, transform, and apply functions on this object.\n",
      "     |  \n",
      "     |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = groupby(obj, ...)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  obj : pandas object\n",
      "     |  axis : int, default 0\n",
      "     |  level : int, default None\n",
      "     |      Level of MultiIndex\n",
      "     |  groupings : list of Grouping objects\n",
      "     |      Most users should ignore this\n",
      "     |  exclusions : array-like, optional\n",
      "     |      List of columns to exclude\n",
      "     |  name : str\n",
      "     |      Most users should ignore this\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  **Attributes**\n",
      "     |  groups : dict\n",
      "     |      {group name -> group labels}\n",
      "     |  len(grouped) : int\n",
      "     |      Number of groups\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      "     |  some other brief notes about usage. When grouping by multiple groups, the\n",
      "     |  result index will be a MultiIndex (hierarchical) by default.\n",
      "     |  \n",
      "     |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      "     |  you can write code like:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = obj.groupby(keys, axis=axis)\n",
      "     |      for key, group in grouped:\n",
      "     |          # do something with the data\n",
      "     |  \n",
      "     |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      "     |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      "     |  method on each group, you can simply do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).std()\n",
      "     |  \n",
      "     |  rather than\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).aggregate(np.std)\n",
      "     |  \n",
      "     |  You can pass arguments to these \"wrapped\" functions, too.\n",
      "     |  \n",
      "     |  See the online documentation for full exposition on these topics and much\n",
      "     |  more\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupBy\n",
      "     |      _GroupBy\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  all(self, skipna: bool = True)\n",
      "     |      Return True if all values in the group are truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  any(self, skipna: bool = True)\n",
      "     |      Return True if any value in the group is truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  backfill(self, limit=None)\n",
      "     |      Backward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.backfill\n",
      "     |      DataFrame.backfill\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  bfill = backfill(self, limit=None)\n",
      "     |  \n",
      "     |  count(self)\n",
      "     |      Compute count of group, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Count of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumcount(self, ascending: bool = True)\n",
      "     |      Number each item in each group from 0 to the length of that group - 1.\n",
      "     |      \n",
      "     |      Essentially this is equivalent to\n",
      "     |      \n",
      "     |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from length of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Sequence number of each element within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .ngroup : Number the groups themselves.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      "     |      ...                   columns=['A'])\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').cumcount()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    0\n",
      "     |      4    1\n",
      "     |      5    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').cumcount(ascending=False)\n",
      "     |      0    3\n",
      "     |      1    2\n",
      "     |      2    1\n",
      "     |      3    1\n",
      "     |      4    0\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  cummax(self, axis=0, **kwargs)\n",
      "     |      Cumulative max for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cummin(self, axis=0, **kwargs)\n",
      "     |      Cumulative min for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumprod(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative product for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumsum(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative sum for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  describe(self, **kwargs)\n",
      "     |      Generate descriptive statistics.\n",
      "     |      \n",
      "     |      Descriptive statistics include those that summarize the central\n",
      "     |      tendency, dispersion and shape of a\n",
      "     |      dataset's distribution, excluding ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Summary statistics of the Series or Dataframe provided.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count: Count number of non-NA/null observations.\n",
      "     |      DataFrame.max: Maximum of the values in the object.\n",
      "     |      DataFrame.min: Minimum of the values in the object.\n",
      "     |      DataFrame.mean: Mean of the values.\n",
      "     |      DataFrame.std: Standard deviation of the observations.\n",
      "     |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      "     |          columns based on their dtype.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      "     |      ...                    'numeric': [1, 2, 3],\n",
      "     |      ...                    'object': ['a', 'b', 'c']\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |             categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |  \n",
      "     |  expanding(self, *args, **kwargs)\n",
      "     |      Return an expanding grouper, providing expanding\n",
      "     |      functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ffill = pad(self, limit=None)\n",
      "     |  \n",
      "     |  first(self, **kwargs)\n",
      "     |      Compute first of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed first of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return first n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').head(1)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      2  5  6\n",
      "     |      >>> df.groupby('A').head(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  last(self, **kwargs)\n",
      "     |      Compute last of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed last of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  max(self, **kwargs)\n",
      "     |      Compute max of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed max of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  mean(self, *args, **kwargs)\n",
      "     |      Compute mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pandas.Series or pandas.DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      "     |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of the remaining columns in\n",
      "     |      each group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A').mean()\n",
      "     |           B         C\n",
      "     |      A\n",
      "     |      1  3.0  1.333333\n",
      "     |      2  4.0  1.500000\n",
      "     |      \n",
      "     |      Groupby two columns and return the mean of the remaining column.\n",
      "     |      \n",
      "     |      >>> df.groupby(['A', 'B']).mean()\n",
      "     |             C\n",
      "     |      A B\n",
      "     |      1 2.0  2\n",
      "     |        4.0  1\n",
      "     |      2 3.0  1\n",
      "     |        5.0  2\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of only particular column in\n",
      "     |      the group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A')['B'].mean()\n",
      "     |      A\n",
      "     |      1    3.0\n",
      "     |      2    4.0\n",
      "     |      Name: B, dtype: float64\n",
      "     |  \n",
      "     |  median(self, **kwargs)\n",
      "     |      Compute median of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Median of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  min(self, **kwargs)\n",
      "     |      Compute min of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed min of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  ngroup(self, ascending: bool = True)\n",
      "     |      Number each group from 0 to the number of groups - 1.\n",
      "     |      \n",
      "     |      This is the enumerative complement of cumcount.  Note that the\n",
      "     |      numbers given to the groups match the order in which the groups\n",
      "     |      would be seen when iterating over the groupby object, not the\n",
      "     |      order they are first observed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from number of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Unique numbers for each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .cumcount : Number the rows in each group.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    0\n",
      "     |      3    1\n",
      "     |      4    1\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').ngroup(ascending=False)\n",
      "     |      0    1\n",
      "     |      1    1\n",
      "     |      2    1\n",
      "     |      3    0\n",
      "     |      4    0\n",
      "     |      5    1\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    1\n",
      "     |      3    3\n",
      "     |      4    2\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  nth(self, n: Union[int, List[int]], dropna: Union[str, NoneType] = None) -> pandas.core.frame.DataFrame\n",
      "     |      Take the nth row from each group if n is an int, or a subset of rows\n",
      "     |      if n is a list of ints.\n",
      "     |      \n",
      "     |      If dropna, will take the nth non-null row, dropna is either\n",
      "     |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      "     |      before the groupby.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or list of ints\n",
      "     |          A single nth value for the row or a list of nth values.\n",
      "     |      dropna : None or str, optional\n",
      "     |          Apply the specified dropna operation before counting which row is\n",
      "     |          the nth row. Needs to be None, 'any' or 'all'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          N-th value within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      "     |      >>> g = df.groupby('A')\n",
      "     |      >>> g.nth(0)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      2  3.0\n",
      "     |      >>> g.nth(1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth(-1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  4.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth([0, 1])\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      2  5.0\n",
      "     |      \n",
      "     |      Specifying `dropna` allows count ignoring ``NaN``\n",
      "     |      \n",
      "     |      >>> g.nth(0, dropna='any')\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      \n",
      "     |      NaNs denote group exhausted when using dropna\n",
      "     |      \n",
      "     |      >>> g.nth(3, dropna='any')\n",
      "     |          B\n",
      "     |      A\n",
      "     |      1 NaN\n",
      "     |      2 NaN\n",
      "     |      \n",
      "     |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      "     |      \n",
      "     |      >>> df.groupby('A', as_index=False).nth(1)\n",
      "     |         A    B\n",
      "     |      1  1  2.0\n",
      "     |      4  2  5.0\n",
      "     |  \n",
      "     |  ohlc(self) -> pandas.core.frame.DataFrame\n",
      "     |      Compute sum of values, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          Open, high, low and close values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  pad(self, limit=None)\n",
      "     |      Forward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pad\n",
      "     |      DataFrame.pad\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, axis=0)\n",
      "     |      Calculate pct_change of each value to previous entry in group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Percentage changes within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  prod(self, **kwargs)\n",
      "     |      Compute prod of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed prod of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, interpolation: str = 'linear')\n",
      "     |      Return group values at the given quantile, a la numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          Method to use when the desired quantile falls between two points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Return type determined by caller of GroupBy object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.quantile : Similar method for Series.\n",
      "     |      DataFrame.quantile : Similar method for DataFrame.\n",
      "     |      numpy.percentile : NumPy method to compute qth percentile.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([\n",
      "     |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      "     |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      "     |      ... ], columns=['key', 'val'])\n",
      "     |      >>> df.groupby('key').quantile()\n",
      "     |          val\n",
      "     |      key\n",
      "     |      a    2.0\n",
      "     |      b    3.0\n",
      "     |  \n",
      "     |  rank(self, method: str = 'average', ascending: bool = True, na_option: str = 'keep', pct: bool = False, axis: int = 0)\n",
      "     |      Provide the rank of values within each group.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      "     |          * average: average rank of group.\n",
      "     |          * min: lowest rank in group.\n",
      "     |          * max: highest rank in group.\n",
      "     |          * first: ranks assigned in order they appear in the array.\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      "     |      ascending : bool, default True\n",
      "     |          False for ranks by high (1) to low (N).\n",
      "     |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      "     |          * keep: leave NA values where they are.\n",
      "     |          * top: smallest rank if ascending.\n",
      "     |          * bottom: smallest rank if descending.\n",
      "     |      pct : bool, default False\n",
      "     |          Compute percentage rank of data within each group.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis of the object over which to compute the rank.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame with ranking of values within each group\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  resample(self, rule, *args, **kwargs)\n",
      "     |      Provide resampling when using a TimeGrouper.\n",
      "     |      \n",
      "     |      Given a grouper, the function resamples it according to a string\n",
      "     |      \"string\" -> \"frequency\".\n",
      "     |      \n",
      "     |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      "     |      documentation for more details.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : str or DateOffset\n",
      "     |          The offset string or object representing target grouper conversion.\n",
      "     |      *args, **kwargs\n",
      "     |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      "     |          `on`, and other arguments of `TimeGrouper`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Grouper\n",
      "     |          Return a new grouper with our resampler appended.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Grouper : Specify a frequency to resample with when\n",
      "     |          grouping by a key.\n",
      "     |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      "     |          time series.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      "     |      ...                   index=idx,\n",
      "     |      ...                   columns=['a', 'b'])\n",
      "     |      >>> df.iloc[2, 0] = 5\n",
      "     |      >>> df\n",
      "     |                          a  b\n",
      "     |      2000-01-01 00:00:00  0  1\n",
      "     |      2000-01-01 00:01:00  0  1\n",
      "     |      2000-01-01 00:02:00  5  1\n",
      "     |      2000-01-01 00:03:00  0  1\n",
      "     |      \n",
      "     |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      "     |      the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  2\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('30S').sum()\n",
      "     |                          a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:00:30  0  0\n",
      "     |          2000-01-01 00:01:00  0  1\n",
      "     |          2000-01-01 00:01:30  0  0\n",
      "     |          2000-01-01 00:02:00  0  0\n",
      "     |          2000-01-01 00:02:30  0  0\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:02:00  5  1\n",
      "     |      \n",
      "     |      Resample by month. Values are assigned to the month of the period.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('M').sum()\n",
      "     |                  a  b\n",
      "     |      a\n",
      "     |      0   2000-01-31  0  3\n",
      "     |      5   2000-01-31  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   1999-12-31 23:57:00  0  1\n",
      "     |          2000-01-01 00:00:00  0  2\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and close the right side of\n",
      "     |      the bin interval, but label each bin using the right edge instead of\n",
      "     |      the left.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:03:00  0  2\n",
      "     |      5   2000-01-01 00:03:00  5  1\n",
      "     |      \n",
      "     |      Add an offset of twenty seconds.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      "     |                             a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:20  0  2\n",
      "     |          2000-01-01 00:03:20  0  1\n",
      "     |      5   2000-01-01 00:00:20  5  1\n",
      "     |  \n",
      "     |  rolling(self, *args, **kwargs)\n",
      "     |      Return a rolling grouper, providing rolling functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sem(self, ddof: int = 1)\n",
      "     |      Compute standard error of the mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard error of the mean of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      "     |      Shift each group by periods observations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Number of periods to shift.\n",
      "     |      freq : frequency string\n",
      "     |      axis : axis to shift, default 0\n",
      "     |      fill_value : optional\n",
      "     |      \n",
      "     |          .. versionadded:: 0.24.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object shifted within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  size(self)\n",
      "     |      Compute group sizes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Number of rows in each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  std(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute standard deviation of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard deviation of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sum(self, **kwargs)\n",
      "     |      Compute sum of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed sum of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return last n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').tail(1)\n",
      "     |         A  B\n",
      "     |      1  a  2\n",
      "     |      3  b  2\n",
      "     |      >>> df.groupby('A').tail(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  var(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute variance of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Variance of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _GroupBy:\n",
      "     |  \n",
      "     |  __getattr__(self, attr: str)\n",
      "     |  \n",
      "     |  __init__(self, obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Groupby iterator.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Generator yielding sequence of (name, subsetted object)\n",
      "     |      for each group\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return a string representation for a particular object.\n",
      "     |  \n",
      "     |  apply(self, func, *args, **kwargs)\n",
      "     |      Apply function `func`  group-wise and combine the results together.\n",
      "     |      \n",
      "     |      The function passed to `apply` must take a dataframe as its first\n",
      "     |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      "     |      then take care of combining the results back together into a single\n",
      "     |      dataframe or series. `apply` is therefore a highly flexible\n",
      "     |      grouping method.\n",
      "     |      \n",
      "     |      While `apply` is a very flexible method, its downside is that\n",
      "     |      using it can be quite a bit slower than using more specific methods\n",
      "     |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      "     |      be much faster than using `apply` for their specific purposes, so try to\n",
      "     |      use them before reaching for `apply`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable\n",
      "     |          A callable that takes a dataframe as its first argument, and\n",
      "     |          returns a dataframe, a series or a scalar. In addition the\n",
      "     |          callable may take positional and keyword arguments.\n",
      "     |      args, kwargs : tuple and dict\n",
      "     |          Optional positional and keyword arguments to pass to `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pipe : Apply function to the full GroupBy object instead of to each\n",
      "     |          group.\n",
      "     |      aggregate : Apply aggregate function to the GroupBy object.\n",
      "     |      transform : Apply function column-by-column to the GroupBy object.\n",
      "     |      Series.apply : Apply a function to a Series.\n",
      "     |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      "     |  \n",
      "     |  get_group(self, name, obj=None)\n",
      "     |      Construct DataFrame from group with provided name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : object\n",
      "     |          The name of the group to get as a DataFrame.\n",
      "     |      obj : DataFrame, default None\n",
      "     |          The DataFrame to take the DataFrame out of.  If\n",
      "     |          it is None, the object groupby was called on will\n",
      "     |          be used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group : same type as obj\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply a function `func` with arguments to this GroupBy object and return\n",
      "     |      the function's result.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Use `.pipe` when you want to improve readability by chaining together\n",
      "     |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      "     |      Instead of writing\n",
      "     |      \n",
      "     |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.groupby('group')\n",
      "     |      ...    .pipe(f)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(h, arg2=b, arg3=c))\n",
      "     |      \n",
      "     |      which is much more readable.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable or tuple of (callable, string)\n",
      "     |          Function to apply to this GroupBy object or, alternatively,\n",
      "     |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      "     |          string indicating the keyword of `callable` that expects the\n",
      "     |          GroupBy object.\n",
      "     |      args : iterable, optional\n",
      "     |             Positional arguments passed into `func`.\n",
      "     |      kwargs : dict, optional\n",
      "     |               A dictionary of keyword arguments passed into `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of `func`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pipe : Apply a function with arguments to a series.\n",
      "     |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      "     |      apply : Apply function to each group instead of to the\n",
      "     |          full GroupBy object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See more `here\n",
      "     |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  1\n",
      "     |      1  b  2\n",
      "     |      2  a  3\n",
      "     |      3  b  4\n",
      "     |      \n",
      "     |      To get the difference between each groups maximum and minimum value in one\n",
      "     |      pass, you can do\n",
      "     |      \n",
      "     |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      "     |         B\n",
      "     |      A\n",
      "     |      a  2\n",
      "     |      b  2\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _GroupBy:\n",
      "     |  \n",
      "     |  groups\n",
      "     |      Dict {group name -> group labels}.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Dict {group name -> group indices}.\n",
      "     |  \n",
      "     |  ngroups\n",
      "     |  \n",
      "     |  plot\n",
      "     |      Class implementing the .plot attribute for groupby objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _GroupBy:\n",
      "     |  \n",
      "     |  __annotations__ = {'_apply_whitelist': typing.FrozenSet[str]}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  agg = aggregate(self, func, *args, **kwargs)\n",
      "     |  \n",
      "     |  aggregate(self, func, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      "     |  \n",
      "     |  ndim\n",
      "    \n",
      "    class Grouper(builtins.object)\n",
      "     |  Grouper(*args, **kwargs)\n",
      "     |  \n",
      "     |  A Grouper allows the user to specify a groupby instruction for an object.\n",
      "     |  \n",
      "     |  This specification will select a column via the key parameter, or if the\n",
      "     |  level and/or axis parameters are given, a level of the index of the target\n",
      "     |  object.\n",
      "     |  \n",
      "     |  If `axis` and/or `level` are passed as keywords to both `Grouper` and\n",
      "     |  `groupby`, the values passed to `Grouper` take precedence.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  key : str, defaults to None\n",
      "     |      Groupby key, which selects the grouping column of the target.\n",
      "     |  level : name/number, defaults to None\n",
      "     |      The level for the target index.\n",
      "     |  freq : str / frequency object, defaults to None\n",
      "     |      This will groupby the specified frequency if the target selection\n",
      "     |      (via key or level) is a datetime-like object. For full specification\n",
      "     |      of available frequencies, please see `here\n",
      "     |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`_.\n",
      "     |  axis : str, int, defaults to 0\n",
      "     |      Number/name of the axis.\n",
      "     |  sort : bool, default to False\n",
      "     |      Whether to sort the resulting labels.\n",
      "     |  closed : {'left' or 'right'}\n",
      "     |      Closed end of interval. Only when `freq` parameter is passed.\n",
      "     |  label : {'left' or 'right'}\n",
      "     |      Interval boundary to use for labeling.\n",
      "     |      Only when `freq` parameter is passed.\n",
      "     |  convention : {'start', 'end', 'e', 's'}\n",
      "     |      If grouper is PeriodIndex and `freq` parameter is passed.\n",
      "     |  base : int, default 0\n",
      "     |      Only when `freq` parameter is passed.\n",
      "     |  loffset : str, DateOffset, timedelta object\n",
      "     |      Only when `freq` parameter is passed.\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  A specification for a groupby instruction\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Syntactic sugar for ``df.groupby('A')``\n",
      "     |  \n",
      "     |  >>> df.groupby(Grouper(key='A'))\n",
      "     |  \n",
      "     |  Specify a resample operation on the column 'date'\n",
      "     |  \n",
      "     |  >>> df.groupby(Grouper(key='date', freq='60s'))\n",
      "     |  \n",
      "     |  Specify a resample operation on the level 'date' on the columns axis\n",
      "     |  with a frequency of 60s\n",
      "     |  \n",
      "     |  >>> df.groupby(Grouper(level='date', freq='60s', axis=1))\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, key=None, level=None, freq=None, axis=0, sort=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, *args, **kwargs)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  ax\n",
      "     |  \n",
      "     |  groups\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'_attributes': typing.Tuple[str, ...]}\n",
      "    \n",
      "    class NamedAgg(builtins.tuple)\n",
      "     |  NamedAgg(column, aggfunc)\n",
      "     |  \n",
      "     |  NamedAgg(column, aggfunc)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NamedAgg\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new NamedAgg object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new NamedAgg object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(_cls, column, aggfunc)\n",
      "     |      Create new instance of NamedAgg(column, aggfunc)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  column\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  aggfunc\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _field_defaults = {}\n",
      "     |  \n",
      "     |  _fields = ('column', 'aggfunc')\n",
      "     |  \n",
      "     |  _fields_defaults = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |  \n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |      \n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class SeriesGroupBy(pandas.core.groupby.groupby.GroupBy)\n",
      "     |  SeriesGroupBy(obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |  \n",
      "     |  Class for grouping and aggregating relational data.\n",
      "     |  \n",
      "     |  See aggregate, transform, and apply functions on this object.\n",
      "     |  \n",
      "     |  It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = groupby(obj, ...)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  obj : pandas object\n",
      "     |  axis : int, default 0\n",
      "     |  level : int, default None\n",
      "     |      Level of MultiIndex\n",
      "     |  groupings : list of Grouping objects\n",
      "     |      Most users should ignore this\n",
      "     |  exclusions : array-like, optional\n",
      "     |      List of columns to exclude\n",
      "     |  name : str\n",
      "     |      Most users should ignore this\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  **Attributes**\n",
      "     |  groups : dict\n",
      "     |      {group name -> group labels}\n",
      "     |  len(grouped) : int\n",
      "     |      Number of groups\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  After grouping, see aggregate, apply, and transform functions. Here are\n",
      "     |  some other brief notes about usage. When grouping by multiple groups, the\n",
      "     |  result index will be a MultiIndex (hierarchical) by default.\n",
      "     |  \n",
      "     |  Iteration produces (key, group) tuples, i.e. chunking the data by group. So\n",
      "     |  you can write code like:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      grouped = obj.groupby(keys, axis=axis)\n",
      "     |      for key, group in grouped:\n",
      "     |          # do something with the data\n",
      "     |  \n",
      "     |  Function calls on GroupBy, if not specially implemented, \"dispatch\" to the\n",
      "     |  grouped data. So if you group a DataFrame and wish to invoke the std()\n",
      "     |  method on each group, you can simply do:\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).std()\n",
      "     |  \n",
      "     |  rather than\n",
      "     |  \n",
      "     |  ::\n",
      "     |  \n",
      "     |      df.groupby(mapper).aggregate(np.std)\n",
      "     |  \n",
      "     |  You can pass arguments to these \"wrapped\" functions, too.\n",
      "     |  \n",
      "     |  See the online documentation for full exposition on these topics and much\n",
      "     |  more\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SeriesGroupBy\n",
      "     |      pandas.core.groupby.groupby.GroupBy\n",
      "     |      pandas.core.groupby.groupby._GroupBy\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      pandas.core.base.SelectionMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  agg = aggregate(self, func=None, *args, **kwargs)\n",
      "     |  \n",
      "     |  aggregate(self, func=None, *args, **kwargs)\n",
      "     |      Aggregate using one or more operations over the specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function, str, list or dict\n",
      "     |          Function to use for aggregating the data. If a function, must either\n",
      "     |          work when passed a Series or when passed to Series.apply.\n",
      "     |      \n",
      "     |          Accepted combinations are:\n",
      "     |      \n",
      "     |          - function\n",
      "     |          - string function name\n",
      "     |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      "     |          - dict of axis labels -> functions, function names or list of such.\n",
      "     |      \n",
      "     |      *args\n",
      "     |          Positional arguments to pass to `func`.\n",
      "     |      **kwargs\n",
      "     |          Keyword arguments to pass to `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar, Series or DataFrame\n",
      "     |      \n",
      "     |          The return can be:\n",
      "     |      \n",
      "     |          * scalar : when Series.agg is called with single function\n",
      "     |          * Series : when DataFrame.agg is called with a single function\n",
      "     |          * DataFrame : when DataFrame.agg is called with several functions\n",
      "     |      \n",
      "     |          Return scalar, Series or DataFrame.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.Series.groupby.apply\n",
      "     |      pandas.Series.groupby.transform\n",
      "     |      pandas.Series.aggregate\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `agg` is an alias for `aggregate`. Use the alias.\n",
      "     |      \n",
      "     |      A passed user-defined-function will be passed a Series for evaluation.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series([1, 2, 3, 4])\n",
      "     |      \n",
      "     |      >>> s\n",
      "     |      0    1\n",
      "     |      1    2\n",
      "     |      2    3\n",
      "     |      3    4\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s.groupby([1, 1, 2, 2]).min()\n",
      "     |      1    1\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s.groupby([1, 1, 2, 2]).agg('min')\n",
      "     |      1    1\n",
      "     |      2    3\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      >>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])\n",
      "     |         min  max\n",
      "     |      1    1    2\n",
      "     |      2    3    4\n",
      "     |      \n",
      "     |      The output column names can be controlled by passing\n",
      "     |      the desired column names and aggregations as keyword arguments.\n",
      "     |      \n",
      "     |      >>> s.groupby([1, 1, 2, 2]).agg(\n",
      "     |      ...     minimum='min',\n",
      "     |      ...     maximum='max',\n",
      "     |      ... )\n",
      "     |         minimum  maximum\n",
      "     |      1        1        2\n",
      "     |      2        3        4\n",
      "     |  \n",
      "     |  apply(self, func, *args, **kwargs)\n",
      "     |      Apply function `func`  group-wise and combine the results together.\n",
      "     |      \n",
      "     |      The function passed to `apply` must take a series as its first\n",
      "     |      argument and return a DataFrame, Series or scalar. `apply` will\n",
      "     |      then take care of combining the results back together into a single\n",
      "     |      dataframe or series. `apply` is therefore a highly flexible\n",
      "     |      grouping method.\n",
      "     |      \n",
      "     |      While `apply` is a very flexible method, its downside is that\n",
      "     |      using it can be quite a bit slower than using more specific methods\n",
      "     |      like `agg` or `transform`. Pandas offers a wide range of method that will\n",
      "     |      be much faster than using `apply` for their specific purposes, so try to\n",
      "     |      use them before reaching for `apply`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable\n",
      "     |          A callable that takes a series as its first argument, and\n",
      "     |          returns a dataframe, a series or a scalar. In addition the\n",
      "     |          callable may take positional and keyword arguments.\n",
      "     |      args, kwargs : tuple and dict\n",
      "     |          Optional positional and keyword arguments to pass to `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      applied : Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pipe : Apply function to the full GroupBy object instead of to each\n",
      "     |          group.\n",
      "     |      aggregate : Apply aggregate function to the GroupBy object.\n",
      "     |      transform : Apply function column-by-column to the GroupBy object.\n",
      "     |      Series.apply : Apply a function to a Series.\n",
      "     |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      "     |  \n",
      "     |  count(self) -> pandas.core.series.Series\n",
      "     |      Compute count of group, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Count of values within each group.\n",
      "     |  \n",
      "     |  describe(self, **kwargs)\n",
      "     |      Generate descriptive statistics.\n",
      "     |      \n",
      "     |      Descriptive statistics include those that summarize the central\n",
      "     |      tendency, dispersion and shape of a\n",
      "     |      dataset's distribution, excluding ``NaN`` values.\n",
      "     |      \n",
      "     |      Analyzes both numeric and object series, as well\n",
      "     |      as ``DataFrame`` column sets of mixed data types. The output\n",
      "     |      will vary depending on what is provided. Refer to the notes\n",
      "     |      below for more detail.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      percentiles : list-like of numbers, optional\n",
      "     |          The percentiles to include in the output. All should\n",
      "     |          fall between 0 and 1. The default is\n",
      "     |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      "     |          75th percentiles.\n",
      "     |      include : 'all', list-like of dtypes or None (default), optional\n",
      "     |          A white list of data types to include in the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - 'all' : All columns of the input will be included in the output.\n",
      "     |          - A list-like of dtypes : Limits the results to the\n",
      "     |            provided data types.\n",
      "     |            To limit the result to numeric types submit\n",
      "     |            ``numpy.number``. To limit it instead to object columns submit\n",
      "     |            the ``numpy.object`` data type. Strings\n",
      "     |            can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            select pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will include all numeric columns.\n",
      "     |      exclude : list-like of dtypes or None (default), optional,\n",
      "     |          A black list of data types to omit from the result. Ignored\n",
      "     |          for ``Series``. Here are the options:\n",
      "     |      \n",
      "     |          - A list-like of dtypes : Excludes the provided data types\n",
      "     |            from the result. To exclude numeric types submit\n",
      "     |            ``numpy.number``. To exclude object columns submit the data\n",
      "     |            type ``numpy.object``. Strings can also be used in the style of\n",
      "     |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      "     |            exclude pandas categorical columns, use ``'category'``\n",
      "     |          - None (default) : The result will exclude nothing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Summary statistics of the Series or Dataframe provided.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.count: Count number of non-NA/null observations.\n",
      "     |      DataFrame.max: Maximum of the values in the object.\n",
      "     |      DataFrame.min: Minimum of the values in the object.\n",
      "     |      DataFrame.mean: Mean of the values.\n",
      "     |      DataFrame.std: Standard deviation of the observations.\n",
      "     |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      "     |          columns based on their dtype.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For numeric data, the result's index will include ``count``,\n",
      "     |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      "     |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      "     |      upper percentile is ``75``. The ``50`` percentile is the\n",
      "     |      same as the median.\n",
      "     |      \n",
      "     |      For object data (e.g. strings or timestamps), the result's index\n",
      "     |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      "     |      is the most common value. The ``freq`` is the most common value's\n",
      "     |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      "     |      \n",
      "     |      If multiple object values have the highest count, then the\n",
      "     |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      "     |      among those with the highest count.\n",
      "     |      \n",
      "     |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      "     |      return only an analysis of numeric columns. If the dataframe consists\n",
      "     |      only of object and categorical data without any numeric columns, the\n",
      "     |      default is to return an analysis of both the object and categorical\n",
      "     |      columns. If ``include='all'`` is provided as an option, the result\n",
      "     |      will include a union of attributes of each type.\n",
      "     |      \n",
      "     |      The `include` and `exclude` parameters can be used to limit\n",
      "     |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      "     |      The parameters are ignored when analyzing a ``Series``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Describing a numeric ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 2, 3])\n",
      "     |      >>> s.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Describing a categorical ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      "     |      >>> s.describe()\n",
      "     |      count     4\n",
      "     |      unique    3\n",
      "     |      top       a\n",
      "     |      freq      2\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a timestamp ``Series``.\n",
      "     |      \n",
      "     |      >>> s = pd.Series([\n",
      "     |      ...   np.datetime64(\"2000-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\"),\n",
      "     |      ...   np.datetime64(\"2010-01-01\")\n",
      "     |      ... ])\n",
      "     |      >>> s.describe()\n",
      "     |      count                       3\n",
      "     |      unique                      2\n",
      "     |      top       2010-01-01 00:00:00\n",
      "     |      freq                        2\n",
      "     |      first     2000-01-01 00:00:00\n",
      "     |      last      2010-01-01 00:00:00\n",
      "     |      dtype: object\n",
      "     |      \n",
      "     |      Describing a ``DataFrame``. By default only numeric fields\n",
      "     |      are returned.\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      "     |      ...                    'numeric': [1, 2, 3],\n",
      "     |      ...                    'object': ['a', 'b', 'c']\n",
      "     |      ...                   })\n",
      "     |      >>> df.describe()\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      "     |      \n",
      "     |      >>> df.describe(include='all')\n",
      "     |              categorical  numeric object\n",
      "     |      count            3      3.0      3\n",
      "     |      unique           3      NaN      3\n",
      "     |      top              f      NaN      c\n",
      "     |      freq             1      NaN      1\n",
      "     |      mean           NaN      2.0    NaN\n",
      "     |      std            NaN      1.0    NaN\n",
      "     |      min            NaN      1.0    NaN\n",
      "     |      25%            NaN      1.5    NaN\n",
      "     |      50%            NaN      2.0    NaN\n",
      "     |      75%            NaN      2.5    NaN\n",
      "     |      max            NaN      3.0    NaN\n",
      "     |      \n",
      "     |      Describing a column from a ``DataFrame`` by accessing it as\n",
      "     |      an attribute.\n",
      "     |      \n",
      "     |      >>> df.numeric.describe()\n",
      "     |      count    3.0\n",
      "     |      mean     2.0\n",
      "     |      std      1.0\n",
      "     |      min      1.0\n",
      "     |      25%      1.5\n",
      "     |      50%      2.0\n",
      "     |      75%      2.5\n",
      "     |      max      3.0\n",
      "     |      Name: numeric, dtype: float64\n",
      "     |      \n",
      "     |      Including only numeric columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.number])\n",
      "     |             numeric\n",
      "     |      count      3.0\n",
      "     |      mean       2.0\n",
      "     |      std        1.0\n",
      "     |      min        1.0\n",
      "     |      25%        1.5\n",
      "     |      50%        2.0\n",
      "     |      75%        2.5\n",
      "     |      max        3.0\n",
      "     |      \n",
      "     |      Including only string columns in a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=[np.object])\n",
      "     |             object\n",
      "     |      count       3\n",
      "     |      unique      3\n",
      "     |      top         c\n",
      "     |      freq        1\n",
      "     |      \n",
      "     |      Including only categorical columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(include=['category'])\n",
      "     |             categorical\n",
      "     |      count            3\n",
      "     |      unique           3\n",
      "     |      top              f\n",
      "     |      freq             1\n",
      "     |      \n",
      "     |      Excluding numeric columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.number])\n",
      "     |             categorical object\n",
      "     |      count            3      3\n",
      "     |      unique           3      3\n",
      "     |      top              f      c\n",
      "     |      freq             1      1\n",
      "     |      \n",
      "     |      Excluding object columns from a ``DataFrame`` description.\n",
      "     |      \n",
      "     |      >>> df.describe(exclude=[np.object])\n",
      "     |             categorical  numeric\n",
      "     |      count            3      3.0\n",
      "     |      unique           3      NaN\n",
      "     |      top              f      NaN\n",
      "     |      freq             1      NaN\n",
      "     |      mean           NaN      2.0\n",
      "     |      std            NaN      1.0\n",
      "     |      min            NaN      1.0\n",
      "     |      25%            NaN      1.5\n",
      "     |      50%            NaN      2.0\n",
      "     |      75%            NaN      2.5\n",
      "     |      max            NaN      3.0\n",
      "     |  \n",
      "     |  filter(self, func, dropna=True, *args, **kwargs)\n",
      "     |      Return a copy of a Series excluding elements from groups that\n",
      "     |      do not satisfy the boolean criterion specified by func.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : function\n",
      "     |          To apply to each group. Should return True or False.\n",
      "     |      dropna : Drop groups that do not pass the filter. True by default;\n",
      "     |          if False, groups that evaluate False are filled with NaNs.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      "     |      ...                           'foo', 'bar'],\n",
      "     |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      "     |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      "     |      >>> grouped = df.groupby('A')\n",
      "     |      >>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)\n",
      "     |      1    2\n",
      "     |      3    4\n",
      "     |      5    6\n",
      "     |      Name: B, dtype: int64\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      filtered : Series\n",
      "     |  \n",
      "     |  nunique(self, dropna: bool = True) -> pandas.core.series.Series\n",
      "     |      Return number of unique elements in the group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Number of unique values within each group.\n",
      "     |  \n",
      "     |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None)\n",
      "     |      Calculate pct_change of each value to previous entry in group\n",
      "     |  \n",
      "     |  transform(self, func, *args, **kwargs)\n",
      "     |      Call function producing a like-indexed Series on each group and\n",
      "     |      return a Series having the same indexes as the original object\n",
      "     |      filled with the transformed values\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      f : function\n",
      "     |          Function to apply to each group\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      aggregate, transform\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Each group is endowed the attribute 'name' in case you need to know\n",
      "     |      which group you are working on.\n",
      "     |      \n",
      "     |      The current implementation imposes three requirements on f:\n",
      "     |      \n",
      "     |      * f must return a value that either has the same shape as the input\n",
      "     |        subframe or can be broadcast to the shape of the input subframe.\n",
      "     |        For example, if `f` returns a scalar it will be broadcast to have the\n",
      "     |        same shape as the input subframe.\n",
      "     |      * if this is a DataFrame, f must support application column-by-column\n",
      "     |        in the subframe. If f also supports application to the entire subframe,\n",
      "     |        then a fast path is used starting from the second chunk.\n",
      "     |      * f must not mutate groups. Mutation is not supported and may\n",
      "     |        produce unexpected results.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      # Same shape\n",
      "     |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      "     |      ...                           'foo', 'bar'],\n",
      "     |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      "     |      ...                          'two', 'two'],\n",
      "     |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      "     |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      "     |      >>> grouped = df.groupby('A')\n",
      "     |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      "     |                C         D\n",
      "     |      0 -1.154701 -0.577350\n",
      "     |      1  0.577350  0.000000\n",
      "     |      2  0.577350  1.154701\n",
      "     |      3 -1.154701 -1.000000\n",
      "     |      4  0.577350 -0.577350\n",
      "     |      5  0.577350  1.000000\n",
      "     |      \n",
      "     |      # Broadcastable\n",
      "     |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      "     |         C    D\n",
      "     |      0  4  6.0\n",
      "     |      1  3  8.0\n",
      "     |      2  4  6.0\n",
      "     |      3  3  8.0\n",
      "     |      4  4  6.0\n",
      "     |      5  3  8.0\n",
      "     |  \n",
      "     |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  corr\n",
      "     |      Compute correlation with `other` Series, excluding missing values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |          Series with which to compute the correlation.\n",
      "     |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      "     |          Method used to compute correlation:\n",
      "     |      \n",
      "     |          - pearson : Standard correlation coefficient\n",
      "     |          - kendall : Kendall Tau correlation coefficient\n",
      "     |          - spearman : Spearman rank correlation\n",
      "     |          - callable: Callable with input two 1d ndarrays and returning a float.\n",
      "     |      \n",
      "     |          .. versionadded:: 0.24.0\n",
      "     |              Note that the returned matrix from corr will have 1 along the\n",
      "     |              diagonals and will be symmetric regardless of the callable's\n",
      "     |              behavior.\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          Correlation with other.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> def histogram_intersection(a, b):\n",
      "     |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      "     |      ...     return v\n",
      "     |      >>> s1 = pd.Series([.2, .0, .6, .2])\n",
      "     |      >>> s2 = pd.Series([.3, .6, .0, .1])\n",
      "     |      >>> s1.corr(s2, method=histogram_intersection)\n",
      "     |      0.3\n",
      "     |  \n",
      "     |  cov\n",
      "     |      Compute covariance with Series, excluding missing values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : Series\n",
      "     |          Series with which to compute the covariance.\n",
      "     |      min_periods : int, optional\n",
      "     |          Minimum number of observations needed to have a valid result.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      float\n",
      "     |          Covariance between Series and other normalized by N-1\n",
      "     |          (unbiased estimator).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
      "     |      >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
      "     |      >>> s1.cov(s2)\n",
      "     |      -0.01685762652715874\n",
      "     |  \n",
      "     |  diff\n",
      "     |      First discrete difference of element.\n",
      "     |      \n",
      "     |      Calculates the difference of a Series element compared with another\n",
      "     |      element in the Series (default is element in previous row).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Periods to shift for calculating difference, accepts negative\n",
      "     |          values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          First differences of the Series.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pct_change: Percent change over given number of periods.\n",
      "     |      Series.shift: Shift index by desired number of periods with an\n",
      "     |          optional time freq.\n",
      "     |      DataFrame.diff: First discrete difference of object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      "     |      :meth:`operator.sub`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Difference with previous row\n",
      "     |      \n",
      "     |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      "     |      >>> s.diff()\n",
      "     |      0    NaN\n",
      "     |      1    0.0\n",
      "     |      2    1.0\n",
      "     |      3    1.0\n",
      "     |      4    2.0\n",
      "     |      5    3.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Difference with 3rd previous row\n",
      "     |      \n",
      "     |      >>> s.diff(periods=3)\n",
      "     |      0    NaN\n",
      "     |      1    NaN\n",
      "     |      2    NaN\n",
      "     |      3    2.0\n",
      "     |      4    4.0\n",
      "     |      5    6.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      Difference with following row\n",
      "     |      \n",
      "     |      >>> s.diff(periods=-1)\n",
      "     |      0    0.0\n",
      "     |      1   -1.0\n",
      "     |      2   -1.0\n",
      "     |      3   -2.0\n",
      "     |      4   -3.0\n",
      "     |      5    NaN\n",
      "     |      dtype: float64\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Return the dtype object of the underlying data.\n",
      "     |  \n",
      "     |  fillna\n",
      "     |      Fill NA/NaN values using the specified method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      value : scalar, dict, Series, or DataFrame\n",
      "     |          Value to use to fill holes (e.g. 0), alternately a\n",
      "     |          dict/Series/DataFrame of values specifying which value to use for\n",
      "     |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      "     |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      "     |          be a list.\n",
      "     |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "     |          Method to use for filling holes in reindexed Series\n",
      "     |          pad / ffill: propagate last valid observation forward to next valid\n",
      "     |          backfill / bfill: use next valid observation to fill gap.\n",
      "     |      axis : {0 or 'index'}\n",
      "     |          Axis along which to fill missing values.\n",
      "     |      inplace : bool, default False\n",
      "     |          If True, fill in-place. Note: this will modify any\n",
      "     |          other views on this object (e.g., a no-copy slice for a column in a\n",
      "     |          DataFrame).\n",
      "     |      limit : int, default None\n",
      "     |          If method is specified, this is the maximum number of consecutive\n",
      "     |          NaN values to forward/backward fill. In other words, if there is\n",
      "     |          a gap with more than this number of consecutive NaNs, it will only\n",
      "     |          be partially filled. If method is not specified, this is the\n",
      "     |          maximum number of entries along the entire axis where NaNs will be\n",
      "     |          filled. Must be greater than 0 if not None.\n",
      "     |      downcast : dict, default is None\n",
      "     |          A dict of item->dtype of what to downcast if possible,\n",
      "     |          or the string 'infer' which will try to downcast to an appropriate\n",
      "     |          equal type (e.g. float64 to int64 if possible).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or None\n",
      "     |          Object with missing values filled or None if ``inplace=True``.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      interpolate : Fill NaN values using interpolation.\n",
      "     |      reindex : Conform object to new index.\n",
      "     |      asfreq : Convert TimeSeries to specified frequency.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "     |      ...                    [3, 4, np.nan, 1],\n",
      "     |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      "     |      ...                    [np.nan, 3, np.nan, 4]],\n",
      "     |      ...                   columns=list('ABCD'))\n",
      "     |      >>> df\n",
      "     |           A    B   C  D\n",
      "     |      0  NaN  2.0 NaN  0\n",
      "     |      1  3.0  4.0 NaN  1\n",
      "     |      2  NaN  NaN NaN  5\n",
      "     |      3  NaN  3.0 NaN  4\n",
      "     |      \n",
      "     |      Replace all NaN elements with 0s.\n",
      "     |      \n",
      "     |      >>> df.fillna(0)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 0.0 0\n",
      "     |      1   3.0 4.0 0.0 1\n",
      "     |      2   0.0 0.0 0.0 5\n",
      "     |      3   0.0 3.0 0.0 4\n",
      "     |      \n",
      "     |      We can also propagate non-null values forward or backward.\n",
      "     |      \n",
      "     |      >>> df.fillna(method='ffill')\n",
      "     |          A   B   C   D\n",
      "     |      0   NaN 2.0 NaN 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   3.0 4.0 NaN 5\n",
      "     |      3   3.0 3.0 NaN 4\n",
      "     |      \n",
      "     |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "     |      2, and 3 respectively.\n",
      "     |      \n",
      "     |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "     |      >>> df.fillna(value=values)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 2.0 1\n",
      "     |      2   0.0 1.0 2.0 5\n",
      "     |      3   0.0 3.0 2.0 4\n",
      "     |      \n",
      "     |      Only replace the first NaN element.\n",
      "     |      \n",
      "     |      >>> df.fillna(value=values, limit=1)\n",
      "     |          A   B   C   D\n",
      "     |      0   0.0 2.0 2.0 0\n",
      "     |      1   3.0 4.0 NaN 1\n",
      "     |      2   NaN 1.0 NaN 5\n",
      "     |      3   NaN 3.0 NaN 4\n",
      "     |  \n",
      "     |  hist\n",
      "     |      Draw histogram of the input series using matplotlib.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      by : object, optional\n",
      "     |          If passed, then used to form histograms for separate groups.\n",
      "     |      ax : matplotlib axis object\n",
      "     |          If not passed, uses gca().\n",
      "     |      grid : bool, default True\n",
      "     |          Whether to show axis grid lines.\n",
      "     |      xlabelsize : int, default None\n",
      "     |          If specified changes the x-axis label size.\n",
      "     |      xrot : float, default None\n",
      "     |          Rotation of x axis labels.\n",
      "     |      ylabelsize : int, default None\n",
      "     |          If specified changes the y-axis label size.\n",
      "     |      yrot : float, default None\n",
      "     |          Rotation of y axis labels.\n",
      "     |      figsize : tuple, default None\n",
      "     |          Figure size in inches by default.\n",
      "     |      bins : int or sequence, default 10\n",
      "     |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      "     |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      "     |          bin edges, including left edge of first bin and right edge of last\n",
      "     |          bin. In this case, bins is returned unmodified.\n",
      "     |      backend : str, default None\n",
      "     |          Backend to use instead of the backend specified in the option\n",
      "     |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      "     |          specify the ``plotting.backend`` for the whole session, set\n",
      "     |          ``pd.options.plotting.backend``.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.0.0\n",
      "     |      \n",
      "     |      **kwargs\n",
      "     |          To be passed to the actual plotting function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      matplotlib.AxesSubplot\n",
      "     |          A histogram plot.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      "     |  \n",
      "     |  idxmax\n",
      "     |      Return the row label of the maximum value.\n",
      "     |      \n",
      "     |      If multiple values equal the maximum, the first row label with that\n",
      "     |      value is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, default 0\n",
      "     |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      "     |          on Series.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      *args, **kwargs\n",
      "     |          Additional arguments and keywords have no effect but might be\n",
      "     |          accepted for compatibility with NumPy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Index\n",
      "     |          Label of the maximum value.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the Series is empty.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmax : Return indices of the maximum values\n",
      "     |          along the given axis.\n",
      "     |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      "     |          over requested axis.\n",
      "     |      Series.idxmin : Return index *label* of the first occurrence\n",
      "     |          of minimum of values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmax``. This method\n",
      "     |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmax()``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      "     |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      "     |      >>> s\n",
      "     |      A    1.0\n",
      "     |      B    NaN\n",
      "     |      C    4.0\n",
      "     |      D    3.0\n",
      "     |      E    4.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> s.idxmax()\n",
      "     |      'C'\n",
      "     |      \n",
      "     |      If `skipna` is False and there is an NA value in the data,\n",
      "     |      the function returns ``nan``.\n",
      "     |      \n",
      "     |      >>> s.idxmax(skipna=False)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  idxmin\n",
      "     |      Return the row label of the minimum value.\n",
      "     |      \n",
      "     |      If multiple values equal the minimum, the first row label with that\n",
      "     |      value is returned.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, default 0\n",
      "     |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      "     |          on Series.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values. If the entire Series is NA, the result\n",
      "     |          will be NA.\n",
      "     |      *args, **kwargs\n",
      "     |          Additional arguments and keywords have no effect but might be\n",
      "     |          accepted for compatibility with NumPy.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Index\n",
      "     |          Label of the minimum value.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the Series is empty.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      numpy.argmin : Return indices of the minimum values\n",
      "     |          along the given axis.\n",
      "     |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      "     |          over requested axis.\n",
      "     |      Series.idxmax : Return index *label* of the first occurrence\n",
      "     |          of maximum of values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method is the Series version of ``ndarray.argmin``. This method\n",
      "     |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      "     |      the position. To get the position, use ``series.values.argmin()``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      "     |      ...               index=['A', 'B', 'C', 'D'])\n",
      "     |      >>> s\n",
      "     |      A    1.0\n",
      "     |      B    NaN\n",
      "     |      C    4.0\n",
      "     |      D    1.0\n",
      "     |      dtype: float64\n",
      "     |      \n",
      "     |      >>> s.idxmin()\n",
      "     |      'A'\n",
      "     |      \n",
      "     |      If `skipna` is False and there is an NA value in the data,\n",
      "     |      the function returns ``nan``.\n",
      "     |      \n",
      "     |      >>> s.idxmin(skipna=False)\n",
      "     |      nan\n",
      "     |  \n",
      "     |  is_monotonic_decreasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_decreasing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |  \n",
      "     |  is_monotonic_increasing\n",
      "     |      Return boolean if values in the object are\n",
      "     |      monotonic_increasing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |  \n",
      "     |  mad\n",
      "     |      Return the mean absolute deviation of the values for the requested axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |          Axis for the function to be applied on.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar.\n",
      "     |      numeric_only : bool, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to be passed to the function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  nlargest\n",
      "     |      Return the largest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Return this many descending sorted values.\n",
      "     |      keep : {'first', 'last', 'all'}, default 'first'\n",
      "     |          When there are duplicate values that cannot all fit in a\n",
      "     |          Series of `n` elements:\n",
      "     |      \n",
      "     |          - ``first`` : return the first `n` occurrences in order\n",
      "     |              of appearance.\n",
      "     |          - ``last`` : return the last `n` occurrences in reverse\n",
      "     |              order of appearance.\n",
      "     |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      "     |              size larger than `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          The `n` largest values in the Series, sorted in decreasing order.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nsmallest: Get the `n` smallest elements.\n",
      "     |      Series.sort_values: Sort Series by values.\n",
      "     |      Series.head: Return the first `n` rows.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      "     |      relative to the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      "     |      ...                         \"Malta\": 434000, \"Maldives\": 434000,\n",
      "     |      ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n",
      "     |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      "     |      ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n",
      "     |      >>> s = pd.Series(countries_population)\n",
      "     |      >>> s\n",
      "     |      Italy       59000000\n",
      "     |      France      65000000\n",
      "     |      Malta         434000\n",
      "     |      Maldives      434000\n",
      "     |      Brunei        434000\n",
      "     |      Iceland       337000\n",
      "     |      Nauru          11300\n",
      "     |      Tuvalu         11300\n",
      "     |      Anguilla       11300\n",
      "     |      Monserat        5200\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` largest elements where ``n=5`` by default.\n",
      "     |      \n",
      "     |      >>> s.nlargest()\n",
      "     |      France      65000000\n",
      "     |      Italy       59000000\n",
      "     |      Malta         434000\n",
      "     |      Maldives      434000\n",
      "     |      Brunei        434000\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n",
      "     |      so Malta will be kept.\n",
      "     |      \n",
      "     |      >>> s.nlargest(3)\n",
      "     |      France    65000000\n",
      "     |      Italy     59000000\n",
      "     |      Malta       434000\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` largest elements where ``n=3`` and keeping the last duplicates.\n",
      "     |      Brunei will be kept since it is the last with value 434000 based on\n",
      "     |      the index order.\n",
      "     |      \n",
      "     |      >>> s.nlargest(3, keep='last')\n",
      "     |      France      65000000\n",
      "     |      Italy       59000000\n",
      "     |      Brunei        434000\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` largest elements where ``n=3`` with all duplicates kept. Note\n",
      "     |      that the returned Series has five elements due to the three duplicates.\n",
      "     |      \n",
      "     |      >>> s.nlargest(3, keep='all')\n",
      "     |      France      65000000\n",
      "     |      Italy       59000000\n",
      "     |      Malta         434000\n",
      "     |      Maldives      434000\n",
      "     |      Brunei        434000\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  nsmallest\n",
      "     |      Return the smallest `n` elements.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, default 5\n",
      "     |          Return this many ascending sorted values.\n",
      "     |      keep : {'first', 'last', 'all'}, default 'first'\n",
      "     |          When there are duplicate values that cannot all fit in a\n",
      "     |          Series of `n` elements:\n",
      "     |      \n",
      "     |          - ``first`` : return the first `n` occurrences in order\n",
      "     |              of appearance.\n",
      "     |          - ``last`` : return the last `n` occurrences in reverse\n",
      "     |              order of appearance.\n",
      "     |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      "     |              size larger than `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          The `n` smallest values in the Series, sorted in increasing order.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.nlargest: Get the `n` largest elements.\n",
      "     |      Series.sort_values: Sort Series by values.\n",
      "     |      Series.head: Return the first `n` rows.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      "     |      the size of the ``Series`` object.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      "     |      ...                         \"Brunei\": 434000, \"Malta\": 434000,\n",
      "     |      ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n",
      "     |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      "     |      ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n",
      "     |      >>> s = pd.Series(countries_population)\n",
      "     |      >>> s\n",
      "     |      Italy       59000000\n",
      "     |      France      65000000\n",
      "     |      Brunei        434000\n",
      "     |      Malta         434000\n",
      "     |      Maldives      434000\n",
      "     |      Iceland       337000\n",
      "     |      Nauru          11300\n",
      "     |      Tuvalu         11300\n",
      "     |      Anguilla       11300\n",
      "     |      Monserat        5200\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` smallest elements where ``n=5`` by default.\n",
      "     |      \n",
      "     |      >>> s.nsmallest()\n",
      "     |      Monserat      5200\n",
      "     |      Nauru        11300\n",
      "     |      Tuvalu       11300\n",
      "     |      Anguilla     11300\n",
      "     |      Iceland     337000\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` smallest elements where ``n=3``. Default `keep` value is\n",
      "     |      'first' so Nauru and Tuvalu will be kept.\n",
      "     |      \n",
      "     |      >>> s.nsmallest(3)\n",
      "     |      Monserat     5200\n",
      "     |      Nauru       11300\n",
      "     |      Tuvalu      11300\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` smallest elements where ``n=3`` and keeping the last\n",
      "     |      duplicates. Anguilla and Tuvalu will be kept since they are the last\n",
      "     |      with value 11300 based on the index order.\n",
      "     |      \n",
      "     |      >>> s.nsmallest(3, keep='last')\n",
      "     |      Monserat     5200\n",
      "     |      Anguilla    11300\n",
      "     |      Tuvalu      11300\n",
      "     |      dtype: int64\n",
      "     |      \n",
      "     |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n",
      "     |      that the returned Series has four elements due to the three duplicates.\n",
      "     |      \n",
      "     |      >>> s.nsmallest(3, keep='all')\n",
      "     |      Monserat     5200\n",
      "     |      Nauru       11300\n",
      "     |      Tuvalu      11300\n",
      "     |      Anguilla    11300\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  skew\n",
      "     |      Return unbiased skew over requested axis.\n",
      "     |      \n",
      "     |      Normalized by N-1.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : {index (0)}\n",
      "     |          Axis for the function to be applied on.\n",
      "     |      skipna : bool, default True\n",
      "     |          Exclude NA/null values when computing the result.\n",
      "     |      level : int or level name, default None\n",
      "     |          If the axis is a MultiIndex (hierarchical), count along a\n",
      "     |          particular level, collapsing into a scalar.\n",
      "     |      numeric_only : bool, default None\n",
      "     |          Include only float, int, boolean columns. If None, will attempt to use\n",
      "     |          everything, then use only numeric data. Not implemented for Series.\n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments to be passed to the function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      scalar or Series (if level specified)\n",
      "     |  \n",
      "     |  take\n",
      "     |      Return the elements in the given *positional* indices along an axis.\n",
      "     |      \n",
      "     |      This means that we are not indexing according to actual values in\n",
      "     |      the index attribute of the object. We are indexing according to the\n",
      "     |      actual position of the element in the object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      indices : array-like\n",
      "     |          An array of ints indicating which positions to take.\n",
      "     |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      "     |          The axis on which to select elements. ``0`` means that we are\n",
      "     |          selecting rows, ``1`` means that we are selecting columns.\n",
      "     |      is_copy : bool\n",
      "     |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      "     |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      "     |          ``take`` always returns a copy, and the keyword is therefore\n",
      "     |          deprecated.\n",
      "     |      \n",
      "     |          .. deprecated:: 1.0.0\n",
      "     |      **kwargs\n",
      "     |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      "     |          output.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      taken : same type as caller\n",
      "     |          An array-like containing the elements taken from the object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      "     |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      "     |      numpy.take : Take elements from an array along an axis.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      "     |      ...                    ('parrot', 'bird', 24.0),\n",
      "     |      ...                    ('lion', 'mammal', 80.5),\n",
      "     |      ...                    ('monkey', 'mammal', np.nan)],\n",
      "     |      ...                   columns=['name', 'class', 'max_speed'],\n",
      "     |      ...                   index=[0, 2, 3, 1])\n",
      "     |      >>> df\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      2  parrot    bird       24.0\n",
      "     |      3    lion  mammal       80.5\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      "     |      \n",
      "     |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      "     |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      "     |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      "     |      \n",
      "     |      >>> df.take([0, 3])\n",
      "     |           name   class  max_speed\n",
      "     |      0  falcon    bird      389.0\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      \n",
      "     |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      "     |      \n",
      "     |      >>> df.take([1, 2], axis=1)\n",
      "     |          class  max_speed\n",
      "     |      0    bird      389.0\n",
      "     |      2    bird       24.0\n",
      "     |      3  mammal       80.5\n",
      "     |      1  mammal        NaN\n",
      "     |      \n",
      "     |      We may take elements using negative integers for positive indices,\n",
      "     |      starting from the end of the object, just like with Python lists.\n",
      "     |      \n",
      "     |      >>> df.take([-1, -2])\n",
      "     |           name   class  max_speed\n",
      "     |      1  monkey  mammal        NaN\n",
      "     |      3    lion  mammal       80.5\n",
      "     |  \n",
      "     |  tshift\n",
      "     |      Shift the time index, using the index's frequency if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int\n",
      "     |          Number of periods to move, can be positive or negative.\n",
      "     |      freq : DateOffset, timedelta, or str, default None\n",
      "     |          Increment to use from the tseries module\n",
      "     |          or time rule expressed as a string (e.g. 'EOM').\n",
      "     |      axis : {0 or index, 1 or columns, None}, default 0\n",
      "     |          Corresponds to the axis that contains the Index.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      shifted : Series/DataFrame\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If freq is not specified then tries to use the freq or inferred_freq\n",
      "     |      attributes of the index. If neither of those attributes exist, a\n",
      "     |      ValueError is thrown\n",
      "     |  \n",
      "     |  unique\n",
      "     |      Return unique values of Series object.\n",
      "     |      \n",
      "     |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      "     |      therefore does NOT sort.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray or ExtensionArray\n",
      "     |          The unique values returned as a NumPy array. See Notes.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      unique : Top-level unique method for any 1-d array-like object.\n",
      "     |      Index.unique : Return Index with unique values from an Index object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Returns the unique values as a NumPy array. In case of an\n",
      "     |      extension-array backed Series, a new\n",
      "     |      :class:`~api.extensions.ExtensionArray` of that type with just\n",
      "     |      the unique values is returned. This includes\n",
      "     |      \n",
      "     |          * Categorical\n",
      "     |          * Period\n",
      "     |          * Datetime with Timezone\n",
      "     |          * Interval\n",
      "     |          * Sparse\n",
      "     |          * IntegerNA\n",
      "     |      \n",
      "     |      See Examples section.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      "     |      array([2, 1, 3])\n",
      "     |      \n",
      "     |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      "     |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      "     |      \n",
      "     |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      "     |      ...            for _ in range(3)]).unique()\n",
      "     |      <DatetimeArray>\n",
      "     |      ['2016-01-01 00:00:00-05:00']\n",
      "     |      Length: 1, dtype: datetime64[ns, US/Eastern]\n",
      "     |      \n",
      "     |      An unordered Categorical will return categories in the order of\n",
      "     |      appearance.\n",
      "     |      \n",
      "     |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      "     |      [b, a, c]\n",
      "     |      Categories (3, object): [b, a, c]\n",
      "     |      \n",
      "     |      An ordered Categorical preserves the category ordering.\n",
      "     |      \n",
      "     |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      "     |      ...                          ordered=True)).unique()\n",
      "     |      [b, a, c]\n",
      "     |      Categories (3, object): [a < b < c]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      "     |  \n",
      "     |  all(self, skipna: bool = True)\n",
      "     |      Return True if all values in the group are truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  any(self, skipna: bool = True)\n",
      "     |      Return True if any value in the group is truthful, else False.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skipna : bool, default True\n",
      "     |          Flag to ignore nan values during truth testing.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bool\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  backfill(self, limit=None)\n",
      "     |      Backward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.backfill\n",
      "     |      DataFrame.backfill\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  bfill = backfill(self, limit=None)\n",
      "     |  \n",
      "     |  cumcount(self, ascending: bool = True)\n",
      "     |      Number each item in each group from 0 to the length of that group - 1.\n",
      "     |      \n",
      "     |      Essentially this is equivalent to\n",
      "     |      \n",
      "     |      >>> self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from length of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Sequence number of each element within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .ngroup : Number the groups themselves.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      "     |      ...                   columns=['A'])\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').cumcount()\n",
      "     |      0    0\n",
      "     |      1    1\n",
      "     |      2    2\n",
      "     |      3    0\n",
      "     |      4    1\n",
      "     |      5    3\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').cumcount(ascending=False)\n",
      "     |      0    3\n",
      "     |      1    2\n",
      "     |      2    1\n",
      "     |      3    1\n",
      "     |      4    0\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  cummax(self, axis=0, **kwargs)\n",
      "     |      Cumulative max for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cummin(self, axis=0, **kwargs)\n",
      "     |      Cumulative min for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumprod(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative product for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  cumsum(self, axis=0, *args, **kwargs)\n",
      "     |      Cumulative sum for each group.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  expanding(self, *args, **kwargs)\n",
      "     |      Return an expanding grouper, providing expanding\n",
      "     |      functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ffill = pad(self, limit=None)\n",
      "     |  \n",
      "     |  first(self, **kwargs)\n",
      "     |      Compute first of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed first of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  head(self, n=5)\n",
      "     |      Return first n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').head(1)\n",
      "     |         A  B\n",
      "     |      0  1  2\n",
      "     |      2  5  6\n",
      "     |      >>> df.groupby('A').head(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  last(self, **kwargs)\n",
      "     |      Compute last of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed last of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  max(self, **kwargs)\n",
      "     |      Compute max of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed max of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  mean(self, *args, **kwargs)\n",
      "     |      Compute mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pandas.Series or pandas.DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      "     |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of the remaining columns in\n",
      "     |      each group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A').mean()\n",
      "     |           B         C\n",
      "     |      A\n",
      "     |      1  3.0  1.333333\n",
      "     |      2  4.0  1.500000\n",
      "     |      \n",
      "     |      Groupby two columns and return the mean of the remaining column.\n",
      "     |      \n",
      "     |      >>> df.groupby(['A', 'B']).mean()\n",
      "     |             C\n",
      "     |      A B\n",
      "     |      1 2.0  2\n",
      "     |        4.0  1\n",
      "     |      2 3.0  1\n",
      "     |        5.0  2\n",
      "     |      \n",
      "     |      Groupby one column and return the mean of only particular column in\n",
      "     |      the group.\n",
      "     |      \n",
      "     |      >>> df.groupby('A')['B'].mean()\n",
      "     |      A\n",
      "     |      1    3.0\n",
      "     |      2    4.0\n",
      "     |      Name: B, dtype: float64\n",
      "     |  \n",
      "     |  median(self, **kwargs)\n",
      "     |      Compute median of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Median of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  min(self, **kwargs)\n",
      "     |      Compute min of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed min of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  ngroup(self, ascending: bool = True)\n",
      "     |      Number each group from 0 to the number of groups - 1.\n",
      "     |      \n",
      "     |      This is the enumerative complement of cumcount.  Note that the\n",
      "     |      numbers given to the groups match the order in which the groups\n",
      "     |      would be seen when iterating over the groupby object, not the\n",
      "     |      order they are first observed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ascending : bool, default True\n",
      "     |          If False, number in reverse, from number of group - 1 to 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Unique numbers for each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      .cumcount : Number the rows in each group.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      "     |      >>> df\n",
      "     |         A\n",
      "     |      0  a\n",
      "     |      1  a\n",
      "     |      2  a\n",
      "     |      3  b\n",
      "     |      4  b\n",
      "     |      5  a\n",
      "     |      >>> df.groupby('A').ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    0\n",
      "     |      3    1\n",
      "     |      4    1\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby('A').ngroup(ascending=False)\n",
      "     |      0    1\n",
      "     |      1    1\n",
      "     |      2    1\n",
      "     |      3    0\n",
      "     |      4    0\n",
      "     |      5    1\n",
      "     |      dtype: int64\n",
      "     |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      "     |      0    0\n",
      "     |      1    0\n",
      "     |      2    1\n",
      "     |      3    3\n",
      "     |      4    2\n",
      "     |      5    0\n",
      "     |      dtype: int64\n",
      "     |  \n",
      "     |  nth(self, n: Union[int, List[int]], dropna: Union[str, NoneType] = None) -> pandas.core.frame.DataFrame\n",
      "     |      Take the nth row from each group if n is an int, or a subset of rows\n",
      "     |      if n is a list of ints.\n",
      "     |      \n",
      "     |      If dropna, will take the nth non-null row, dropna is either\n",
      "     |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      "     |      before the groupby.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or list of ints\n",
      "     |          A single nth value for the row or a list of nth values.\n",
      "     |      dropna : None or str, optional\n",
      "     |          Apply the specified dropna operation before counting which row is\n",
      "     |          the nth row. Needs to be None, 'any' or 'all'.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          N-th value within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      "     |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      "     |      >>> g = df.groupby('A')\n",
      "     |      >>> g.nth(0)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      2  3.0\n",
      "     |      >>> g.nth(1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth(-1)\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  4.0\n",
      "     |      2  5.0\n",
      "     |      >>> g.nth([0, 1])\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  NaN\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      2  5.0\n",
      "     |      \n",
      "     |      Specifying `dropna` allows count ignoring ``NaN``\n",
      "     |      \n",
      "     |      >>> g.nth(0, dropna='any')\n",
      "     |           B\n",
      "     |      A\n",
      "     |      1  2.0\n",
      "     |      2  3.0\n",
      "     |      \n",
      "     |      NaNs denote group exhausted when using dropna\n",
      "     |      \n",
      "     |      >>> g.nth(3, dropna='any')\n",
      "     |          B\n",
      "     |      A\n",
      "     |      1 NaN\n",
      "     |      2 NaN\n",
      "     |      \n",
      "     |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      "     |      \n",
      "     |      >>> df.groupby('A', as_index=False).nth(1)\n",
      "     |         A    B\n",
      "     |      1  1  2.0\n",
      "     |      4  2  5.0\n",
      "     |  \n",
      "     |  ohlc(self) -> pandas.core.frame.DataFrame\n",
      "     |      Compute sum of values, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |          Open, high, low and close values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  pad(self, limit=None)\n",
      "     |      Forward fill the values.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      limit : int, optional\n",
      "     |          Limit of how many values to fill.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object with missing values filled.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pad\n",
      "     |      DataFrame.pad\n",
      "     |      Series.fillna\n",
      "     |      DataFrame.fillna\n",
      "     |  \n",
      "     |  prod(self, **kwargs)\n",
      "     |      Compute prod of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed prod of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  quantile(self, q=0.5, interpolation: str = 'linear')\n",
      "     |      Return group values at the given quantile, a la numpy.percentile.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : float or array-like, default 0.5 (50% quantile)\n",
      "     |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      "     |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      "     |          Method to use when the desired quantile falls between two points.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Return type determined by caller of GroupBy object.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.quantile : Similar method for Series.\n",
      "     |      DataFrame.quantile : Similar method for DataFrame.\n",
      "     |      numpy.percentile : NumPy method to compute qth percentile.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame([\n",
      "     |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      "     |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      "     |      ... ], columns=['key', 'val'])\n",
      "     |      >>> df.groupby('key').quantile()\n",
      "     |          val\n",
      "     |      key\n",
      "     |      a    2.0\n",
      "     |      b    3.0\n",
      "     |  \n",
      "     |  rank(self, method: str = 'average', ascending: bool = True, na_option: str = 'keep', pct: bool = False, axis: int = 0)\n",
      "     |      Provide the rank of values within each group.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      "     |          * average: average rank of group.\n",
      "     |          * min: lowest rank in group.\n",
      "     |          * max: highest rank in group.\n",
      "     |          * first: ranks assigned in order they appear in the array.\n",
      "     |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      "     |      ascending : bool, default True\n",
      "     |          False for ranks by high (1) to low (N).\n",
      "     |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      "     |          * keep: leave NA values where they are.\n",
      "     |          * top: smallest rank if ascending.\n",
      "     |          * bottom: smallest rank if descending.\n",
      "     |      pct : bool, default False\n",
      "     |          Compute percentage rank of data within each group.\n",
      "     |      axis : int, default 0\n",
      "     |          The axis of the object over which to compute the rank.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame with ranking of values within each group\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  resample(self, rule, *args, **kwargs)\n",
      "     |      Provide resampling when using a TimeGrouper.\n",
      "     |      \n",
      "     |      Given a grouper, the function resamples it according to a string\n",
      "     |      \"string\" -> \"frequency\".\n",
      "     |      \n",
      "     |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      "     |      documentation for more details.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rule : str or DateOffset\n",
      "     |          The offset string or object representing target grouper conversion.\n",
      "     |      *args, **kwargs\n",
      "     |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      "     |          `on`, and other arguments of `TimeGrouper`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Grouper\n",
      "     |          Return a new grouper with our resampler appended.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Grouper : Specify a frequency to resample with when\n",
      "     |          grouping by a key.\n",
      "     |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      "     |          time series.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      "     |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      "     |      ...                   index=idx,\n",
      "     |      ...                   columns=['a', 'b'])\n",
      "     |      >>> df.iloc[2, 0] = 5\n",
      "     |      >>> df\n",
      "     |                          a  b\n",
      "     |      2000-01-01 00:00:00  0  1\n",
      "     |      2000-01-01 00:01:00  0  1\n",
      "     |      2000-01-01 00:02:00  5  1\n",
      "     |      2000-01-01 00:03:00  0  1\n",
      "     |      \n",
      "     |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      "     |      the timestamps falling into a bin.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  2\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Upsample the series into 30 second bins.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('30S').sum()\n",
      "     |                          a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:00:30  0  0\n",
      "     |          2000-01-01 00:01:00  0  1\n",
      "     |          2000-01-01 00:01:30  0  0\n",
      "     |          2000-01-01 00:02:00  0  0\n",
      "     |          2000-01-01 00:02:30  0  0\n",
      "     |          2000-01-01 00:03:00  0  1\n",
      "     |      5   2000-01-01 00:02:00  5  1\n",
      "     |      \n",
      "     |      Resample by month. Values are assigned to the month of the period.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('M').sum()\n",
      "     |                  a  b\n",
      "     |      a\n",
      "     |      0   2000-01-31  0  3\n",
      "     |      5   2000-01-31  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins as above, but close the right\n",
      "     |      side of the bin interval.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   1999-12-31 23:57:00  0  1\n",
      "     |          2000-01-01 00:00:00  0  2\n",
      "     |      5   2000-01-01 00:00:00  5  1\n",
      "     |      \n",
      "     |      Downsample the series into 3 minute bins and close the right side of\n",
      "     |      the bin interval, but label each bin using the right edge instead of\n",
      "     |      the left.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      "     |                               a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:00  0  1\n",
      "     |          2000-01-01 00:03:00  0  2\n",
      "     |      5   2000-01-01 00:03:00  5  1\n",
      "     |      \n",
      "     |      Add an offset of twenty seconds.\n",
      "     |      \n",
      "     |      >>> df.groupby('a').resample('3T', loffset='20s').sum()\n",
      "     |                             a  b\n",
      "     |      a\n",
      "     |      0   2000-01-01 00:00:20  0  2\n",
      "     |          2000-01-01 00:03:20  0  1\n",
      "     |      5   2000-01-01 00:00:20  5  1\n",
      "     |  \n",
      "     |  rolling(self, *args, **kwargs)\n",
      "     |      Return a rolling grouper, providing rolling functionality per group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sem(self, ddof: int = 1)\n",
      "     |      Compute standard error of the mean of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard error of the mean of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      "     |      Shift each group by periods observations.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      periods : int, default 1\n",
      "     |          Number of periods to shift.\n",
      "     |      freq : frequency string\n",
      "     |      axis : axis to shift, default 0\n",
      "     |      fill_value : optional\n",
      "     |      \n",
      "     |          .. versionadded:: 0.24.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Object shifted within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  size(self)\n",
      "     |      Compute group sizes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series\n",
      "     |          Number of rows in each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  std(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute standard deviation of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Standard deviation of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  sum(self, **kwargs)\n",
      "     |      Compute sum of group values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Computed sum of values within each group.\n",
      "     |      \n",
      "     |              See Also\n",
      "     |              --------\n",
      "     |              Series.groupby\n",
      "     |              DataFrame.groupby\n",
      "     |  \n",
      "     |  tail(self, n=5)\n",
      "     |      Return last n rows of each group.\n",
      "     |      \n",
      "     |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      "     |      from the original DataFrame with original index and order preserved\n",
      "     |      (``as_index`` flag is ignored).\n",
      "     |      \n",
      "     |      Does not work for negative values of `n`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      "     |      ...                   columns=['A', 'B'])\n",
      "     |      >>> df.groupby('A').tail(1)\n",
      "     |         A  B\n",
      "     |      1  a  2\n",
      "     |      3  b  2\n",
      "     |      >>> df.groupby('A').tail(-1)\n",
      "     |      Empty DataFrame\n",
      "     |      Columns: [A, B]\n",
      "     |      Index: []\n",
      "     |  \n",
      "     |  var(self, ddof: int = 1, *args, **kwargs)\n",
      "     |      Compute variance of groups, excluding missing values.\n",
      "     |      \n",
      "     |      For multiple groupings, the result index will be a MultiIndex.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ddof : int, default 1\n",
      "     |          Degrees of freedom.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Series or DataFrame\n",
      "     |          Variance of values within each group.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.groupby\n",
      "     |      DataFrame.groupby\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  __getattr__(self, attr: str)\n",
      "     |  \n",
      "     |  __init__(self, obj: pandas.core.generic.NDFrame, keys: Union[Hashable, List[Hashable], Callable[[Hashable], Hashable], List[Callable[[Hashable], Hashable]], Mapping[Hashable, Hashable], NoneType] = None, axis: int = 0, level=None, grouper: 'Optional[ops.BaseGrouper]' = None, exclusions=None, selection=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False, mutated: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Groupby iterator.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Generator yielding sequence of (name, subsetted object)\n",
      "     |      for each group\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return a string representation for a particular object.\n",
      "     |  \n",
      "     |  get_group(self, name, obj=None)\n",
      "     |      Construct DataFrame from group with provided name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name : object\n",
      "     |          The name of the group to get as a DataFrame.\n",
      "     |      obj : DataFrame, default None\n",
      "     |          The DataFrame to take the DataFrame out of.  If\n",
      "     |          it is None, the object groupby was called on will\n",
      "     |          be used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group : same type as obj\n",
      "     |  \n",
      "     |  pipe(self, func, *args, **kwargs)\n",
      "     |      Apply a function `func` with arguments to this GroupBy object and return\n",
      "     |      the function's result.\n",
      "     |      \n",
      "     |      .. versionadded:: 0.21.0\n",
      "     |      \n",
      "     |      Use `.pipe` when you want to improve readability by chaining together\n",
      "     |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      "     |      Instead of writing\n",
      "     |      \n",
      "     |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)\n",
      "     |      \n",
      "     |      You can write\n",
      "     |      \n",
      "     |      >>> (df.groupby('group')\n",
      "     |      ...    .pipe(f)\n",
      "     |      ...    .pipe(g, arg1=a)\n",
      "     |      ...    .pipe(h, arg2=b, arg3=c))\n",
      "     |      \n",
      "     |      which is much more readable.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable or tuple of (callable, string)\n",
      "     |          Function to apply to this GroupBy object or, alternatively,\n",
      "     |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      "     |          string indicating the keyword of `callable` that expects the\n",
      "     |          GroupBy object.\n",
      "     |      args : iterable, optional\n",
      "     |             Positional arguments passed into `func`.\n",
      "     |      kwargs : dict, optional\n",
      "     |               A dictionary of keyword arguments passed into `func`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      object : the return type of `func`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Series.pipe : Apply a function with arguments to a series.\n",
      "     |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      "     |      apply : Apply function to each group instead of to the\n",
      "     |          full GroupBy object.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      See more `here\n",
      "     |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      "     |      >>> df\n",
      "     |         A  B\n",
      "     |      0  a  1\n",
      "     |      1  b  2\n",
      "     |      2  a  3\n",
      "     |      3  b  4\n",
      "     |      \n",
      "     |      To get the difference between each groups maximum and minimum value in one\n",
      "     |      pass, you can do\n",
      "     |      \n",
      "     |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      "     |         B\n",
      "     |      A\n",
      "     |      a  2\n",
      "     |      b  2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  groups\n",
      "     |      Dict {group name -> group labels}.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Dict {group name -> group indices}.\n",
      "     |  \n",
      "     |  ngroups\n",
      "     |  \n",
      "     |  plot\n",
      "     |      Class implementing the .plot attribute for groupby objects.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from pandas.core.groupby.groupby._GroupBy:\n",
      "     |  \n",
      "     |  __annotations__ = {'_apply_whitelist': typing.FrozenSet[str]}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Provide method name lookup and completion.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      "     |  \n",
      "     |  ndim\n",
      "\n",
      "DATA\n",
      "    __all__ = ['DataFrameGroupBy', 'NamedAgg', 'SeriesGroupBy', 'GroupBy',...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\april\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.core.groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combo Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bug</th>\n",
       "      <td>856</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Electric</th>\n",
       "      <td>124</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Fighting</th>\n",
       "      <td>310</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Fire</th>\n",
       "      <td>145</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Flying</th>\n",
       "      <td>982</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Ice</th>\n",
       "      <td>250</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Poison</th>\n",
       "      <td>205</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Psychic</th>\n",
       "      <td>365</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Rock</th>\n",
       "      <td>331</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Steel</th>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Attack  Defense\n",
       "Combo Type                    \n",
       "Bug               856      942\n",
       "Bug-Electric      124      110\n",
       "Bug-Fighting      310      190\n",
       "Bug-Fire          145      120\n",
       "Bug-Flying        982      862\n",
       "...               ...      ...\n",
       "Water-Ice         250      340\n",
       "Water-Poison      205      175\n",
       "Water-Psychic     365      520\n",
       "Water-Rock        331      451\n",
       "Water-Steel        86       88\n",
       "\n",
       "[154 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon.groupby([\"Combo Type\"])[[\"Attack\", \"Defense\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each of the `Combo Type` values obtained from the previous question, calculate the mean scores of all numeric fields across all pokemons.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "![Aggregate](aggregated-mean.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>A/D Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combo Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bug</th>\n",
       "      <td>361.352941</td>\n",
       "      <td>289.705882</td>\n",
       "      <td>53.058824</td>\n",
       "      <td>50.352941</td>\n",
       "      <td>55.411765</td>\n",
       "      <td>39.294118</td>\n",
       "      <td>43.647059</td>\n",
       "      <td>47.941176</td>\n",
       "      <td>3.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Electric</th>\n",
       "      <td>595.500000</td>\n",
       "      <td>395.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Fighting</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Fire</th>\n",
       "      <td>636.500000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.234266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bug-Flying</th>\n",
       "      <td>286.285714</td>\n",
       "      <td>419.500000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>70.142857</td>\n",
       "      <td>61.571429</td>\n",
       "      <td>72.857143</td>\n",
       "      <td>69.071429</td>\n",
       "      <td>82.857143</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.146274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Ice</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>511.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>113.333333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Poison</th>\n",
       "      <td>118.666667</td>\n",
       "      <td>426.666667</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>68.333333</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Psychic</th>\n",
       "      <td>111.800000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Rock</th>\n",
       "      <td>430.000000</td>\n",
       "      <td>428.750000</td>\n",
       "      <td>70.750000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>112.750000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water-Steel</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        #       Total         HP      Attack     Defense  \\\n",
       "Combo Type                                                                 \n",
       "Bug            361.352941  289.705882  53.058824   50.352941   55.411765   \n",
       "Bug-Electric   595.500000  395.500000  60.000000   62.000000   55.000000   \n",
       "Bug-Fighting   214.000000  550.000000  80.000000  155.000000   95.000000   \n",
       "Bug-Fire       636.500000  455.000000  70.000000   72.500000   60.000000   \n",
       "Bug-Flying     286.285714  419.500000  63.000000   70.142857   61.571429   \n",
       "...                   ...         ...        ...         ...         ...   \n",
       "Water-Ice      103.000000  511.666667  90.000000   83.333333  113.333333   \n",
       "Water-Poison   118.666667  426.666667  61.666667   68.333333   58.333333   \n",
       "Water-Psychic  111.800000  481.000000  87.000000   73.000000  104.000000   \n",
       "Water-Rock     430.000000  428.750000  70.750000   82.750000  112.750000   \n",
       "Water-Steel    395.000000  530.000000  84.000000   86.000000   88.000000   \n",
       "\n",
       "                  Sp. Atk     Sp. Def      Speed  Generation  Legendary  \\\n",
       "Combo Type                                                                \n",
       "Bug             39.294118   43.647059  47.941176    3.470588        0.0   \n",
       "Bug-Electric    77.000000   55.000000  86.500000    5.000000        0.0   \n",
       "Bug-Fighting    40.000000  100.000000  80.000000    2.000000        0.0   \n",
       "Bug-Fire        92.500000   80.000000  80.000000    5.000000        0.0   \n",
       "Bug-Flying      72.857143   69.071429  82.857143    2.857143        0.0   \n",
       "...                   ...         ...        ...         ...        ...   \n",
       "Water-Ice       80.000000   78.333333  66.666667    1.000000        0.0   \n",
       "Water-Poison    61.666667   91.666667  85.000000    1.333333        0.0   \n",
       "Water-Psychic   94.000000   79.000000  44.000000    1.200000        0.0   \n",
       "Water-Rock      61.500000   65.000000  36.000000    3.750000        0.0   \n",
       "Water-Steel    111.000000  101.000000  60.000000    4.000000        0.0   \n",
       "\n",
       "               A/D Ratio  \n",
       "Combo Type                \n",
       "Bug             0.940179  \n",
       "Bug-Electric    1.111667  \n",
       "Bug-Fighting    1.637681  \n",
       "Bug-Fire        1.234266  \n",
       "Bug-Flying      1.146274  \n",
       "...                  ...  \n",
       "Water-Ice       0.821759  \n",
       "Water-Poison    1.162149  \n",
       "Water-Psychic   0.783668  \n",
       "Water-Rock      0.727170  \n",
       "Water-Steel     0.977273  \n",
       "\n",
       "[154 rows x 11 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your code here\n",
    "pokemon.groupby([\"Combo Type\"]).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
